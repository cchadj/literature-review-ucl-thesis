
@incollection{krizhevsky_imagenet_2012,
	title = {{ImageNet} Classification with Deep Convolutional Neural Networks},
	url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf},
	pages = {1097--1105},
	booktitle = {Advances in Neural Information Processing Systems 25},
	publisher = {Curran Associates, Inc.},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
	urldate = {2020-02-28},
	date = {2012},
	annotation = {57520 Citations
 }
}

@article{ioffe_batch_2015,
	title = {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
	url = {http://arxiv.org/abs/1502.03167},
	shorttitle = {Batch Normalization},
	abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on {ImageNet} classification: reaching 4.9\% top-5 validation error (and 4.8\% test error), exceeding the accuracy of human raters.},
	journaltitle = {{arXiv}:1502.03167 [cs]},
	author = {Ioffe, Sergey and Szegedy, Christian},
	urldate = {2020-02-28},
	date = {2015-03-02},
	eprinttype = {arxiv},
	eprint = {1502.03167},
	keywords = {Computer Science - Machine Learning},
	annotation = { Cited by 16258}
}

@online{bishop_pattern_2006,
	title = {Pattern recognition and machine learning},
	url = {https://cds.cern.ch/record/998831},
	abstract = {This is the first textbook on pattern recognition to present the Bayesian viewpoint. The book presents approximate inference algorithms that permit fast approximate answers in situations where exact answers are not feasible. It uses graphical models to describe probability distributions when no other books apply graphical models to machine learning. No previous knowledge of pattern recognition or machine learning concepts is assumed. Familiarity with multivariate calculus and basic linear algebra is required, and some experience in the use of probabilities would be helpful though not essential as the book includes a self-contained introduction to basic probability theory.},
	titleaddon = {{CERN} Document Server},
	author = {Bishop, Christopher M.},
	urldate = {2020-02-28},
	date = {2006},
	langid = {english},
	annotation = {Cited by 41367}
}

@article{cunefare_open_2017,
	title = {Open source software for automatic detection of cone photoreceptors in adaptive optics ophthalmoscopy using convolutional neural networks},
	volume = {7},
	rights = {2017 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-017-07103-0},
	doi = {10.1038/s41598-017-07103-0},
	abstract = {Imaging with an adaptive optics scanning light ophthalmoscope ({AOSLO}) enables direct visualization of the cone photoreceptor mosaic in the living human retina. Quantitative analysis of {AOSLO} images typically requires manual grading, which is time consuming, and subjective; thus, automated algorithms are highly desirable. Previously developed automated methods are often reliant on ad hoc rules that may not be transferable between different imaging modalities or retinal locations. In this work, we present a convolutional neural network ({CNN}) based method for cone detection that learns features of interest directly from training data. This cone-identifying algorithm was trained and validated on separate data sets of confocal and split detector {AOSLO} images with results showing performance that closely mimics the gold standard manual process. Further, without any need for algorithmic modifications for a specific {AOSLO} imaging system, our fully-automated multi-modality {CNN}-based cone detection method resulted in comparable results to previous automatic cone segmentation methods which utilized ad hoc rules for different applications. We have made free open-source software for the proposed method and the corresponding training and testing datasets available online.},
	pages = {1--11},
	number = {1},
	journaltitle = {Scientific Reports},
	author = {Cunefare, David and Fang, Leyuan and Cooper, Robert F. and Dubra, Alfredo and Carroll, Joseph and Farsiu, Sina},
	urldate = {2020-02-28},
	date = {2017-07-26},
	langid = {english},
	annotation = {https://github.com/{DavidCunefare}/{CNN}-Cone-Detection},
	annotation = {Sugested by Adam
Cited by 22}
}

@article{ting_artificial_2019,
	title = {Artificial intelligence and deep learning in ophthalmology},
	volume = {103},
	rights = {© Author(s) (or their employer(s)) 2019. Re-use permitted under {CC} {BY}-{NC}. No commercial re-use. See rights and permissions. Published by {BMJ}..  This is an open access article distributed in accordance with the Creative Commons Attribution Non Commercial ({CC} {BY}-{NC} 4.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited, appropriate credit is given, any changes made indicated, and the use is non-commercial. See: http://creativecommons.org/licenses/by-nc/4.0},
	issn = {0007-1161, 1468-2079},
	url = {https://bjo.bmj.com/content/103/2/167},
	doi = {10.1136/bjophthalmol-2018-313173},
	abstract = {Artificial intelligence ({AI}) based on deep learning ({DL}) has sparked tremendous global interest in recent years. {DL} has been widely adopted in image recognition, speech recognition and natural language processing, but is only beginning to impact on healthcare. In ophthalmology, {DL} has been applied to fundus photographs, optical coherence tomography and visual fields, achieving robust classification performance in the detection of diabetic retinopathy and retinopathy of prematurity, the glaucoma-like disc, macular oedema and age-related macular degeneration. {DL} in ocular imaging may be used in conjunction with telemedicine as a possible solution to screen, diagnose and monitor major eye diseases for patients in primary care and community settings. Nonetheless, there are also potential challenges with {DL} application in ophthalmology, including clinical and technical challenges, explainability of the algorithm results, medicolegal issues, and physician and patient acceptance of the {AI} ‘black-box’ algorithms. {DL} could potentially revolutionise how ophthalmology is practised in the future. This review provides a summary of the state-of-the-art {DL} systems described for ophthalmic applications, potential challenges in clinical deployment and the path forward.},
	pages = {167--175},
	number = {2},
	journaltitle = {British Journal of Ophthalmology},
	author = {Ting, Daniel Shu Wei and Pasquale, Louis R. and Peng, Lily and Campbell, John Peter and Lee, Aaron Y. and Raman, Rajiv and Tan, Gavin Siew Wei and Schmetterer, Leopold and Keane, Pearse A. and Wong, Tien Yin},
	urldate = {2020-02-28},
	date = {2019-02-01},
	langid = {english},
	pmid = {30361278},
	keywords = {glaucoma, imaging, public health, retina, telemedicine},
	annotation = {Cited by 77
 }
}

@article{cunefare_deep_2018,
	title = {Deep learning based detection of cone photoreceptors with multimodal adaptive optics scanning light ophthalmoscope images of achromatopsia},
	volume = {9},
	rights = {\&\#169; 2018 Optical Society of America},
	issn = {2156-7085},
	url = {https://www.osapublishing.org/boe/abstract.cfm?uri=boe-9-8-3740},
	doi = {10.1364/BOE.9.003740},
	abstract = {Fast and reliable quantification of cone photoreceptors is a bottleneck in the clinical utilization of adaptive optics scanning light ophthalmoscope ({AOSLO}) systems for the study, diagnosis, and prognosis of retinal diseases. To-date, manual grading has been the sole reliable source of {AOSLO} quantification, as no automatic method has been reliably utilized for cone detection in real-world low-quality images of diseased retina. We present a novel deep learning based approach that combines information from both the confocal and non-confocal split detector {AOSLO} modalities to detect cones in subjects with achromatopsia. Our dual-mode deep learning based approach outperforms the state-of-the-art automated techniques and is on a par with human grading.},
	pages = {3740--3756},
	number = {8},
	journaltitle = {Biomedical Optics Express},
	shortjournal = {Biomed. Opt. Express, {BOE}},
	author = {Cunefare, David and Langlo, Christopher S. and Patterson, Emily J. and Blau, Sarah and Dubra, Alfredo and Carroll, Joseph and Farsiu, Sina},
	urldate = {2020-02-28},
	date = {2018-08-01},
	keywords = {Cone cells, Image processing, Optical coherence tomography, Photoreceptors, Stochastic gradient descent, Visual acuity}
}

@article{ronneberger_u-net_2015,
	title = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
	url = {http://arxiv.org/abs/1505.04597},
	shorttitle = {U-Net},
	abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the {ISBI} challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and {DIC}) we won the {ISBI} cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent {GPU}. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
	journaltitle = {{arXiv}:1505.04597 [cs]},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	urldate = {2020-03-27},
	date = {2015-05-18},
	eprinttype = {arxiv},
	eprint = {1505.04597},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annotation = {Comment: conditionally accepted at {MICCAI} 2015}
}

@incollection{ciresan_deep_2012,
	title = {Deep Neural Networks Segment Neuronal Membranes in Electron Microscopy Images},
	url = {http://papers.nips.cc/paper/4741-deep-neural-networks-segment-neuronal-membranes-in-electron-microscopy-images.pdf},
	pages = {2843--2851},
	booktitle = {Advances in Neural Information Processing Systems 25},
	publisher = {Curran Associates, Inc.},
	author = {Ciresan, Dan and Giusti, Alessandro and Gambardella, Luca M. and Schmidhuber, Jürgen},
	editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
	urldate = {2020-03-28},
	date = {2012}
}

@article{falk_u-net_2019,
	title = {U-Net: deep learning for cell counting, detection, and morphometry},
	volume = {16},
	rights = {2018 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/s41592-018-0261-2},
	doi = {10.1038/s41592-018-0261-2},
	shorttitle = {U-Net},
	abstract = {A user-friendly {ImageJ} plugin enables the application and training of U-Nets for deep-learning-based image segmentation, detection and classification tasks with minimal labeling requirements.},
	pages = {67--70},
	number = {1},
	journaltitle = {Nature Methods},
	author = {Falk, Thorsten and Mai, Dominic and Bensch, Robert and Çiçek, Özgün and Abdulkadir, Ahmed and Marrakchi, Yassine and Böhm, Anton and Deubner, Jan and Jäckel, Zoe and Seiwald, Katharina and Dovzhenko, Alexander and Tietz, Olaf and Dal Bosco, Cristina and Walsh, Sean and Saltukoglu, Deniz and Tay, Tuan Leng and Prinz, Marco and Palme, Klaus and Simons, Matias and Diester, Ilka and Brox, Thomas and Ronneberger, Olaf},
	urldate = {2020-03-28},
	date = {2019-01},
	langid = {english},
	note = {Number: 1
Publisher: Nature Publishing Group}
}

@inproceedings{long_fully_2015,
	title = {Fully Convolutional Networks for Semantic Segmentation},
	url = {https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Long_Fully_Convolutional_Networks_2015_CVPR_paper.html},
	eventtitle = {Proceedings of the {IEEE} Conference on Computer Vision and Pattern Recognition},
	pages = {3431--3440},
	author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
	urldate = {2020-03-28},
	date = {2015}
}

@online{noauthor_notitle_nodate,
	url = {https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf},
	urldate = {2020-03-28}
}

@online{noauthor_notitle_nodate-1,
	url = {https://journals.plos.org/plosone/article/file?type=printable&id=10.1371/journal.pone.0218918},
	urldate = {2020-03-30}
}

@article{patton_retinal_2005,
	title = {Retinal vascular image analysis as a potential screening tool for cerebrovascular disease: a rationale based on homology between cerebral and retinal microvasculatures},
	volume = {206},
	issn = {0021-8782},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1571489/},
	doi = {10.1111/j.1469-7580.2005.00395.x},
	shorttitle = {Retinal vascular image analysis as a potential screening tool for cerebrovascular disease},
	abstract = {The retinal and cerebral microvasculatures share many morphological and physiological properties. Assessment of the cerebral microvasculature requires highly specialized and expensive techniques. The potential for using non-invasive clinical assessment of the retinal microvasculature as a marker of the state of the cerebrovasculature offers clear advantages, owing to the ease with which the retinal vasculature can be directly visualized in vivo and photographed due to its essential two-dimensional nature. The use of retinal digital image analysis is becoming increasingly common, and offers new techniques to analyse different aspects of retinal vascular topography, including retinal vascular widths, geometrical attributes at vessel bifurcations and vessel tracking. Being predominantly automated and objective, these techniques offer an exciting opportunity to study the potential to identify retinal microvascular abnormalities as markers of cerebrovascular pathology. In this review, we describe the anatomical and physiological homology between the retinal and cerebral microvasculatures. We review the evidence that retinal microvascular changes occur in cerebrovascular disease and review current retinal image analysis tools that may allow us to use different aspects of the retinal microvasculature as potential markers for the state of the cerebral microvasculature.},
	pages = {319--348},
	number = {4},
	journaltitle = {Journal of Anatomy},
	shortjournal = {J Anat},
	author = {Patton, Niall and Aslam, Tariq and {MacGillivray}, Thomas and Pattie, Alison and Deary, Ian J and Dhillon, Baljean},
	urldate = {2020-03-30},
	date = {2005-04},
	pmid = {15817102},
	pmcid = {PMC1571489}
}

@article{burns_adaptive_2019,
	title = {Adaptive optics imaging of the human retina},
	volume = {68},
	issn = {1350-9462},
	url = {http://www.sciencedirect.com/science/article/pii/S1350946218300405},
	doi = {10.1016/j.preteyeres.2018.08.002},
	abstract = {Adaptive Optics ({AO}) retinal imaging has provided revolutionary tools to scientists and clinicians for studying retinal structure and function in the living eye. From animal models to clinical patients, {AO} imaging is changing the way scientists are approaching the study of the retina. By providing cellular and subcellular details without the need for histology, it is now possible to perform large scale studies as well as to understand how an individual retina changes over time. Because {AO} retinal imaging is non-invasive and when performed with near-{IR} wavelengths both safe and easily tolerated by patients, it holds promise for being incorporated into clinical trials providing cell specific approaches to monitoring diseases and therapeutic interventions. {AO} is being used to enhance the ability of {OCT}, fluorescence imaging, and reflectance imaging. By incorporating imaging that is sensitive to differences in the scattering properties of retinal tissue, it is especially sensitive to disease, which can drastically impact retinal tissue properties. This review examines human {AO} retinal imaging with a concentration on the use of the Adaptive Optics Scanning Laser Ophthalmoscope ({AOSLO}). It first covers the background and the overall approaches to human {AO} retinal imaging, and the technology involved, and then concentrates on using {AO} retinal imaging to study the structure and function of the retina.},
	pages = {1--30},
	journaltitle = {Progress in Retinal and Eye Research},
	shortjournal = {Progress in Retinal and Eye Research},
	author = {Burns, Stephen A. and Elsner, Ann E. and Sapoznik, Kaitlyn A. and Warner, Raymond L. and Gast, Thomas J.},
	urldate = {2020-03-30},
	date = {2019-01-01},
	langid = {english},
	keywords = {Photoreceptors, Blood flow, Imaging, Ophthalmoscopy, Retina, Retinal degenerations, Vascular disease}
}

@article{chui_use_2012,
	title = {The use of forward scatter to improve retinal vascular imaging with an adaptive optics scanning laser ophthalmoscope},
	volume = {3},
	rights = {\&\#169; 2012 {OSA}},
	issn = {2156-7085},
	url = {https://www.osapublishing.org/boe/abstract.cfm?uri=boe-3-10-2537},
	doi = {10.1364/BOE.3.002537},
	abstract = {Retinal vascular diseases are a leading cause of blindness and visual disability. The advent of adaptive optics retinal imaging has enabled us to image the retinal vascular at cellular resolutions, but imaging of the vasculature can be difficult due to the complex nature of the images, including features of many other retinal structures, such as the nerve fiber layer, glial and other cells. In this paper we show that varying the size and centration of the confocal aperture of an adaptive optics scanning laser ophthalmoscope ({AOSLO}) can increase sensitivity to multiply scattered light, especially light forward scattered from the vasculature and erythrocytes. The resulting technique was tested by imaging regions with different retinal tissue reflectivities as well as within the optic nerve head.},
	pages = {2537--2549},
	number = {10},
	journaltitle = {Biomedical Optics Express},
	shortjournal = {Biomed. Opt. Express, {BOE}},
	author = {Chui, Toco Y. P. and {VanNasdale}, Dean A. and Burns, Stephen A.},
	urldate = {2020-03-30},
	date = {2012-10-01},
	note = {Publisher: Optical Society of America},
	keywords = {Image processing, Visual acuity, Imaging systems, Imaging techniques, Optic nerve, Wave front sensing}
}

@article{castro_rapid_2016,
	title = {Rapid high resolution imaging with a dual-channel scanning technique},
	volume = {41},
	rights = {\&\#169; 2016 Optical Society of America},
	issn = {1539-4794},
	url = {https://www.osapublishing.org/ol/abstract.cfm?uri=ol-41-8-1881},
	doi = {10.1364/OL.41.001881},
	abstract = {A spatial shift between channels in a dual-beam raster-scan imaging system introduces a temporal separation between images from the two channels that can be much shorter than the frame rate of the system. The technique is demonstrated by measuring the velocity of erythrocytes in the retinal capillaries. We used an adaptive optics scanning laser ophthalmoscope and introduced a temporal separation between imaging channels of 4.7 ms. We imaged three subjects and measured changing capillary blood flow velocity at the pulse rate. Since the time shift between channels is easily and continuously adjustable, this method can be used to measure rapidly changing events in any raster scan system with little added complexity.},
	pages = {1881--1884},
	number = {8},
	journaltitle = {Optics Letters},
	shortjournal = {Opt. Lett., {OL}},
	author = {Castro, Alberto de and Huang, Gang and Sawides, Lucie and Luo, Ting and Burns, Stephen A.},
	urldate = {2020-03-30},
	date = {2016-04-15},
	note = {Publisher: Optical Society of America},
	keywords = {Optical coherence tomography, Imaging systems, Imaging techniques, Eye movements, Image registration, Real time imaging}
}

@inproceedings{raina_large-scale_2009,
	location = {Montreal, Quebec, Canada},
	title = {Large-scale deep unsupervised learning using graphics processors},
	isbn = {978-1-60558-516-1},
	url = {https://doi.org/10.1145/1553374.1553486},
	doi = {10.1145/1553374.1553486},
	series = {{ICML} '09},
	abstract = {The promise of unsupervised learning methods lies in their potential to use vast amounts of unlabeled data to learn complex, highly nonlinear models with millions of free parameters. We consider two well-known unsupervised learning models, deep belief networks ({DBNs}) and sparse coding, that have recently been applied to a flurry of machine learning applications (Hinton \& Salakhutdinov, 2006; Raina et al., 2007). Unfortunately, current learning algorithms for both models are too slow for large-scale applications, forcing researchers to focus on smaller-scale models, or to use fewer training examples. In this paper, we suggest massively parallel methods to help resolve these problems. We argue that modern graphics processors far surpass the computational capabilities of multicore {CPUs}, and have the potential to revolutionize the applicability of deep unsupervised learning methods. We develop general principles for massively parallelizing unsupervised learning tasks using graphics processors. We show that these principles can be applied to successfully scaling up learning algorithms for both {DBNs} and sparse coding. Our implementation of {DBN} learning is up to 70 times faster than a dual-core {CPU} implementation for large models. For example, we are able to reduce the time required to learn a four-layer {DBN} with 100 million free parameters from several weeks to around a single day. For sparse coding, we develop a simple, inherently parallel algorithm, that leads to a 5 to 15-fold speedup over previous methods.},
	pages = {873--880},
	booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
	publisher = {Association for Computing Machinery},
	author = {Raina, Rajat and Madhavan, Anand and Ng, Andrew Y.},
	urldate = {2020-03-29},
	date = {2009-06-14}
}

@article{ciresan_deep_2010,
	title = {Deep, Big, Simple Neural Nets for Handwritten Digit Recognition},
	volume = {22},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/NECO_a_00052},
	doi = {10.1162/NECO_a_00052},
	abstract = {Good old online backpropagation for plain multilayer perceptrons yields a very low 0.35\% error rate on the {MNIST} handwritten digits benchmark. All we need to achieve this best result so far are many hidden layers, many neurons per layer, numerous deformed training images to avoid overfitting, and graphics cards to greatly speed up learning.},
	pages = {3207--3220},
	number = {12},
	journaltitle = {Neural Computation},
	shortjournal = {Neural Computation},
	author = {Cireşan, Dan Claudiu and Meier, Ueli and Gambardella, Luca Maria and Schmidhuber, Jürgen},
	urldate = {2020-03-30},
	date = {2010-09-21},
	note = {Publisher: {MIT} Press}
}

@inproceedings{he_deep_2016,
	title = {Deep Residual Learning for Image Recognition},
	booktitle = {The {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	date = {2016-06}
}

@inproceedings{deng_imagenet_2009,
	title = {{ImageNet}: A large-scale hierarchical image database},
	doi = {10.1109/CVPR.2009.5206848},
	shorttitle = {{ImageNet}},
	abstract = {The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called “{ImageNet}”, a large-scale ontology of images built upon the backbone of the {WordNet} structure. {ImageNet} aims to populate the majority of the 80,000 synsets of {WordNet} with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of {WordNet}. This paper offers a detailed analysis of {ImageNet} in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that {ImageNet} is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of {ImageNet} through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of {ImageNet} can offer unparalleled opportunities to researchers in the computer vision community and beyond.},
	eventtitle = {2009 {IEEE} Conference on Computer Vision and Pattern Recognition},
	pages = {248--255},
	booktitle = {2009 {IEEE} Conference on Computer Vision and Pattern Recognition},
	author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
	date = {2009-06},
	note = {{ISSN}: 1063-6919},
	keywords = {computer vision, Explosions, Image databases, image resolution, image retrieval, Image retrieval, {ImageNet} database, Information retrieval, Internet, large-scale hierarchical image database, large-scale ontology, Large-scale systems, multimedia computing, multimedia data, Multimedia databases, Ontologies, ontologies (artificial intelligence), Robustness, Spine, subtree, trees (mathematics), very large databases, visual databases, {wordNet} structure}
}

@inproceedings{dubra_registration_2010,
	location = {Berlin, Heidelberg},
	title = {Registration of 2D Images from Fast Scanning Ophthalmic Instruments},
	isbn = {978-3-642-14366-3},
	doi = {10.1007/978-3-642-14366-3_6},
	series = {Lecture Notes in Computer Science},
	abstract = {Images from high-resolution scanning ophthalmic instruments are significantly distorted due to eye movement. Accurate image registration is required to successfully image subjects who are unable to fixate due to retinal conditions. Moreover, all scanning ophthalmic imaging modalities using adaptive optics will benefit from image registration, even in subjects with good fixation and anaesthetized animals. Transformation functions used to map two images could in principle be very complex. Here, we show that when the scanning in ophthalmic instruments is sufficiently fast with respect to the speed of involuntary eye movement, these mapping functions become the addition of a linear term and a single variable function. Then, based on experimental data on eye movement amplitude and speed of the fixating eye, minimum sampling frequencies for these instruments are discussed. Finally, a simple method for estimating the image transformation functions by taking advantage of the finite bandwidth of the motion signals is presented.},
	pages = {60--71},
	booktitle = {Biomedical Image Registration},
	publisher = {Springer},
	author = {Dubra, Alfredo and Harvey, Zachary},
	editor = {Fischer, Bernd and Dawant, Benoît M. and Lorenz, Cristian},
	date = {2010},
	langid = {english},
	keywords = {Current Frame, Discrete Cosine Transform, Discrete Fourier Transform, Optical Coherence Tomography, Retinal Pigment Epithelial Cell}
}

@article{perez_effectiveness_2017,
	title = {The Effectiveness of Data Augmentation in Image Classification using Deep Learning},
	url = {http://arxiv.org/abs/1712.04621},
	abstract = {In this paper, we explore and compare multiple solutions to the problem of data augmentation in image classification. Previous work has demonstrated the effectiveness of data augmentation through simple techniques, such as cropping, rotating, and flipping input images. We artificially constrain our access to data to a small subset of the {ImageNet} dataset, and compare each data augmentation technique in turn. One of the more successful data augmentations strategies is the traditional transformations mentioned above. We also experiment with {GANs} to generate images of different styles. Finally, we propose a method to allow a neural net to learn augmentations that best improve the classifier, which we call neural augmentation. We discuss the successes and shortcomings of this method on various datasets.},
	journaltitle = {{arXiv}:1712.04621 [cs]},
	author = {Perez, Luis and Wang, Jason},
	urldate = {2020-03-30},
	date = {2017-12-13},
	eprinttype = {arxiv},
	eprint = {1712.04621},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annotation = {Comment: 8 pages, 12 figures}
}

@misc{yilmaz_object_2006,
	title = {Object tracking: A survey},
	url = {https://doi.org/10.1145/1177352.1177355},
	shorttitle = {Object tracking},
	abstract = {The goal of this article is to review the state-of-the-art tracking methods, classify them into different categories, and identify new trends. Object tracking, in general, is a challenging problem. Difficulties in tracking objects can arise due to abrupt object motion, changing appearance patterns of both the object and the scene, nonrigid object structures, object-to-object and object-to-scene occlusions, and camera motion. Tracking is usually performed in the context of higher-level applications that require the location and/or shape of the object in every frame. Typically, assumptions are made to constrain the tracking problem in the context of a particular application. In this survey, we categorize the tracking methods on the basis of the object and motion representations used, provide detailed descriptions of representative methods in each category, and examine their pros and cons. Moreover, we discuss the important issues related to tracking including the use of appropriate image features, selection of motion models, and detection of objects.},
	publisher = {Association for Computing Machinery},
	author = {Yilmaz, Alper and Javed, Omar and Shah, Mubarak},
	urldate = {2020-03-30},
	date = {2006-12-25},
	keywords = {Appearance models, contour evolution, feature selection, object detection, object representation, point tracking, shape tracking}
}

@article{riva_laser_1972,
	title = {Laser Doppler Measurements of Blood Flow in Capillary Tubes and Retinal Arteries},
	volume = {11},
	issn = {1552-5783},
	url = {https://iovs.arvojournals.org/article.aspx?articleid=2122295},
	pages = {936--944},
	number = {11},
	journaltitle = {Investigative Ophthalmology \& Visual Science},
	shortjournal = {Invest. Ophthalmol. Vis. Sci.},
	author = {Riva, Charles and Ross, Benjamin and Benedek, George B.},
	urldate = {2020-04-23},
	date = {1972-11-01},
	langid = {english},
	note = {Publisher: The Association for Research in Vision and Ophthalmology}
}

@article{tam_noninvasive_2010,
	title = {Noninvasive Visualization and Analysis of Parafoveal Capillaries in Humans},
	volume = {51},
	issn = {1552-5783},
	url = {https://iovs.arvojournals.org/article.aspx?articleid=2165417},
	doi = {10.1167/iovs.09-4483},
	pages = {1691--1698},
	number = {3},
	journaltitle = {Investigative Ophthalmology \& Visual Science},
	shortjournal = {Invest. Ophthalmol. Vis. Sci.},
	author = {Tam, Johnny and Martin, Joy A. and Roorda, Austin},
	urldate = {2020-04-24},
	date = {2010-03-01},
	langid = {english},
	note = {Publisher: The Association for Research in Vision and Ophthalmology},
	annotation = {Cited by 192
 }
}

@article{tam_characterization_2011,
	title = {Characterization of single-file flow through human retinal parafoveal capillaries using an adaptive optics scanning laser ophthalmoscope},
	volume = {2},
	rights = {\&\#169; 2011 {OSA}},
	issn = {2156-7085},
	url = {https://www.osapublishing.org/boe/abstract.cfm?uri=boe-2-4-781},
	doi = {10.1364/BOE.2.000781},
	abstract = {Adaptive Optics Scanning Laser Ophthalmoscopy was used to noninvasively acquire videos of single-file flow through live human retinal parafoveal capillaries. Videos were analyzed offline to investigate capillary flow dynamics. Certain capillaries accounted for a clear majority of leukocyte traffic (Leukocyte-Preferred-Paths, {LPPs}), while other capillaries primarily featured plasma gap flow (Plasma-Gap-Capillaries, {PGCs}). {LPPs} may serve as a protective mechanism to prevent inactivated leukocytes from entering exchange capillaries, and {PGCs} may serve as relief valves to minimize flow disruption due to the presence of a leukocyte in a neighboring {LPP}.},
	pages = {781--793},
	number = {4},
	journaltitle = {Biomedical Optics Express},
	shortjournal = {Biomed. Opt. Express, {BOE}},
	author = {Tam, Johnny and Tiruveedhula, Pavan and Roorda, Austin},
	urldate = {2020-04-24},
	date = {2011-04-01},
	note = {Publisher: Optical Society of America},
	keywords = {Adaptive optics, Analytical techniques, Imaging techniques, Network topology, Scanning laser ophthalmoscopy, Spatial resolution},
	annotation = {Cited By 95
 }
}

@article{mizutani_accelerated_diabetes_1996,
	title = {Accelerated death of retinal microvascular cells in human and experimental diabetic retinopathy.},
	volume = {97},
	issn = {0021-9738},
	url = {https://www.jci.org/articles/view/118746},
	doi = {10.1172/JCI118746},
	pages = {2883--2890},
	number = {12},
	journaltitle = {The Journal of Clinical Investigation},
	shortjournal = {J Clin Invest},
	author = {Mizutani, M. and Kern, T. S. and Lorenzi, M.},
	urldate = {2020-04-24},
	date = {1996-06-15},
	langid = {english},
	pmid = {8675702},
	note = {Publisher: American Society for Clinical Investigation}
}


@article{ostergaard_role_stroke_2013,
	title = {The Role of the Cerebral Capillaries in Acute Ischemic Stroke: The Extended Penumbra Model},
	volume = {33},
	issn = {0271-678X},
	url = {https://doi.org/10.1038/jcbfm.2013.18},
	doi = {10.1038/jcbfm.2013.18},
	shorttitle = {The Role of the Cerebral Capillaries in Acute Ischemic Stroke},
	abstract = {The pathophysiology of cerebral ischemia is traditionally understood in relation to reductions in cerebral blood flow ({CBF}). However, a recent reanalysis of the flow-diffusion equation shows that increased capillary transit time heterogeneity ({CTTH}) can reduce the oxygen extraction efficacy in brain tissue for a given {CBF}. Changes in capillary morphology are typical of conditions predisposing to stroke and of experimental ischemia. Changes in capillary flow patterns have been observed by direct microscopy in animal models of ischemia and by indirect methods in humans stroke, but their metabolic significance remain unclear. We modeled the effects of progressive increases in {CTTH} on the way in which brain tissue can secure sufficient oxygen to meet its metabolic needs. Our analysis predicts that as {CTTH} increases, {CBF} responses to functional activation and to vasodilators must be suppressed to maintain sufficient tissue oxygenation. Reductions in {CBF}, increases in {CTTH}, and combinations thereof can seemingly trigger a critical lack of oxygen in brain tissue, and the restoration of capillary perfusion patterns therefore appears to be crucial for the restoration of the tissue oxygenation after ischemic episodes. In this review, we discuss the possible implications of these findings for the prevention, diagnosis, and treatment of acute stroke.},
	pages = {635--648},
	number = {5},
	journaltitle = {Journal of Cerebral Blood Flow \& Metabolism},
	shortjournal = {J Cereb Blood Flow Metab},
	author = {Østergaard, Leif and Jespersen, Sune Nørhøj and Mouridsen, Kim and Mikkelsen, Irene Klærke and Jonsdottír, Kristjana Ýr and Tietze, Anna and Blicher, Jakob Udby and Aamand, Rasmus and Hjort, Niels and Iversen, Nina Kerting and Cai, Changsi and Hougaard, Kristina Dupont and Simonsen, Claus Z and Von Weitzel-Mudersbach, Paul and Modrau, Boris and Nagenthiraja, Kartheeban and Ribe, Lars Riisgaard and Hansen, Mikkel Bo and Bekke, Susanne Lise and Dahlman, Martin Gervais and Puig, Josep and Pedraza, Salvador and Serena, Joaquín and Cho, Tae-Hee and Siemonsen, Susanne and Thomalla, Götz and Fiehler, Jens and Nighoghossian, Norbert and Andersen, Grethe},
	urldate = {2020-04-24},
	date = {2013-05-01},
	langid = {english},
	note = {Publisher: {SAGE} Publications Ltd {STM}}
}

@article{wolf_s_quantification_hypertension_1994,
	title = {Quantification of retinal capillary density and flow velocity in patients with essential hypertension.},
	volume = {23},
	url = {https://www.ahajournals.org/doi/abs/10.1161/01.hyp.23.4.464},
	doi = {10.1161/01.HYP.23.4.464},
	abstract = {Arterial hypertension is known to be an important risk factor for cerebral and cardiovascular disease. Previous studies in rats have demonstrated that changes in both capillary density and vessel diameter may contribute to increased vascular resistance in hypertension. In vivo studies of human subjects with essential hypertension revealed a reduction in the number of arterioles in the skin and conjunctiva; no other in vivo data are available from other tissues. By means of a new imaging technique, capillary density and capillary blood flow velocity can now be assessed in the human retina. We undertook the present investigation to determine whether patients with essential hypertension and only minor clinical retinal vascular alterations have decreased retinal capillary density and altered capillary flow velocity. Seventeen hypertensive patients with only minor retinal vascular alterations and 17 healthy volunteers matched for age were selected. All study participants underwent ophthalmologic examination and fluorescein angiographic studies by means of scanning laser ophthalmoscopy. Capillary density and capillary blood flow velocity in the perifoveal network were evaluated from the angiograms. The retinal microcirculation in the perifoveal capillary network of hypertensive patients showed significant alterations. Both the capillary density and capillary flow velocities were significantly reduced compared with the control group. For the first time alterations of capillary blood flow and capillary density in a vascular network very similar to that of the brain have been demonstrated in hypertensive patients in vivo. Further studies with this technique may help identify patients at high risk for cerebrovascular diseases.},
	pages = {464--467},
	number = {4},
	journaltitle = {Hypertension},
	shortjournal = {Hypertension},
	author = {{Wolf S} and {Arend O} and {Schulte K} and {Ittel T H} and {Reim M}},
	urldate = {2020-04-24},
	date = {1994-04-01},
	note = {Publisher: American Heart Association}
}

@article{de_la_torre_is_alzheimer_2004,
	title = {Is Alzheimer's disease a neurodegenerative or a vascular disorder? Data, dogma, and dialectics},
	volume = {3},
	issn = {1474-4422},
	url = {http://www.sciencedirect.com/science/article/pii/S1474442204006830},
	doi = {10.1016/S1474-4422(04)00683-0},
	shorttitle = {Is Alzheimer's disease a neurodegenerative or a vascular disorder?},
	abstract = {The cause of Alzheimer's disease ({AD}) is unknown. This gap in knowledge has created a stumbling block in the search for a genuinely effective treatment or cure for this dementia. This article summarises the arguments for a causal role for either amyloid deposition or cerebrovascular pathology as the primary trigger in the development of non-genetic {AD}. A bare-bones survey of the published research reveals no compelling evidence that amyloid deposition is neurotoxic in human beings or that it results in neurodegenerative changes involving synaptic, metabolic, or neuronal loss in human or transgenic-mouse brains. By contrast, the data supporting {AD} as a primary vascular disorder are more convincing. Findings suggesting a vascular cause of {AD} come from epidemiological, neuroimaging, pathological, pharmacotherapeutic, and clinical studies. The consensus of these studies indicates that chronic brain hypoperfusion is linked to {AD} risk factors, {AD} preclinical detection and pharmacotherapeutic action of {AD} symptoms.},
	pages = {184--190},
	number = {3},
	journaltitle = {The Lancet Neurology},
	shortjournal = {The Lancet Neurology},
	author = {de la Torre, Jack C},
	urldate = {2020-04-24},
	date = {2004-03-01},
	langid = {english}
}


@article{bateman_comparison_multiple_sclerosis_2016,
	title = {A comparison between the pathophysiology of multiple sclerosis and normal pressure hydrocephalus: is pulse wave encephalopathy a component of {MS}?},
	volume = {13},
	issn = {2045-8118},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5034419/},
	doi = {10.1186/s12987-016-0041-2},
	shorttitle = {A comparison between the pathophysiology of multiple sclerosis and normal pressure hydrocephalus},
	abstract = {Background
	It has been suggested there is a chronic neurodegenerative disorder, underlying the pathophysiology of multiple sclerosis ({MS}), which is distinct from the more obvious immune-mediated attack on the white matter. Limited data exists indicating there is an alteration in pulse wave propagation within the craniospinal cavity in {MS}, similar to the findings in normal pressure hydrocephalus ({NPH}). It is hypothesized {MS} may harbor pulse wave encephalopathy. The purpose of this study is to compare blood flow and pulse wave measurements in {MS} patients with a cohort of {NPH} patients and control subjects, to test this hypothesis.
	
	Methods
	Twenty patients with {MS} underwent magnetic resonance ({MR}) flow quantification techniques. Mean blood flow and stroke volume were measured in the arterial inflow and venous out flow from the sagittal ({SSS}) and straight sinus ({ST}). The arteriovenous delay ({AVD}) was defined. The results were compared with both age-matched controls and {NPH} patients.
	
	Results
	In {MS} there was a 35 \% reduction in arteriovenous delay and a 5 \% reduction in the percentage of the arterial inflow returning via the sagittal sinus compared to age matched controls. There was an alteration in pulse wave propagation, with a 26 \% increase in arterial stroke volume but 30 \% reduction in {SSS} and {ST} stroke volume. The {AVD} and blood flow changes were in the same direction to those of {NPH} patients.
	
	Conclusions
	There are blood flow and pulsation propagation changes in {MS} patients which are similar to those of {NPH} patients. The findings would be consistent with an underlying pulse wave encephalopathy component in {MS}.
	
	Electronic supplementary material
	The online version of this article (doi:10.1186/s12987-016-0041-2) contains supplementary material, which is available to authorized users.},
	journaltitle = {Fluids and Barriers of the {CNS}},
	shortjournal = {Fluids Barriers {CNS}},
	author = {Bateman, Grant A. and Lechner-Scott, Jeannette and Lea, Rodney A.},
	urldate = {2020-04-24},
	date = {2016-09-22},
	pmid = {27658732},
	pmcid = {PMC5034419}
}
@article{patton_retinal_brain_vasculature_similarity_2005,
title = {Retinal vascular image analysis as a potential screening tool for cerebrovascular disease: a rationale based on homology between cerebral and retinal microvasculatures},
volume = {206},
issn = {0021-8782},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1571489/},
doi = {10.1111/j.1469-7580.2005.00395.x},
shorttitle = {Retinal vascular image analysis as a potential screening tool for cerebrovascular disease},
abstract = {The retinal and cerebral microvasculatures share many morphological and physiological properties. Assessment of the cerebral microvasculature requires highly specialized and expensive techniques. The potential for using non-invasive clinical assessment of the retinal microvasculature as a marker of the state of the cerebrovasculature offers clear advantages, owing to the ease with which the retinal vasculature can be directly visualized in vivo and photographed due to its essential two-dimensional nature. The use of retinal digital image analysis is becoming increasingly common, and offers new techniques to analyse different aspects of retinal vascular topography, including retinal vascular widths, geometrical attributes at vessel bifurcations and vessel tracking. Being predominantly automated and objective, these techniques offer an exciting opportunity to study the potential to identify retinal microvascular abnormalities as markers of cerebrovascular pathology. In this review, we describe the anatomical and physiological homology between the retinal and cerebral microvasculatures. We review the evidence that retinal microvascular changes occur in cerebrovascular disease and review current retinal image analysis tools that may allow us to use different aspects of the retinal microvasculature as potential markers for the state of the cerebral microvasculature.},
pages = {319--348},
number = {4},
journaltitle = {Journal of Anatomy},
shortjournal = {J Anat},
author = {Patton, Niall and Aslam, Tariq and {MacGillivray}, Thomas and Pattie, Alison and Deary, Ian J and Dhillon, Baljean},
urldate = {2020-03-30},
date = {2005-04},
pmid = {15817102},
pmcid = {PMC1571489}
}

