
@incollection{krizhevsky_imagenet_2012,
	title = {{ImageNet} Classification with Deep Convolutional Neural Networks},
	url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf},
	pages = {1097--1105},
	booktitle = {Advances in Neural Information Processing Systems 25},
	publisher = {Curran Associates, Inc.},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
	urldate = {2020-02-28},
	date = {2012},
	annotation = {57520 Citations
 }
}

@article{ioffe_batch_2015,
	title = {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
	url = {http://arxiv.org/abs/1502.03167},
	shorttitle = {Batch Normalization},
	abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on {ImageNet} classification: reaching 4.9\% top-5 validation error (and 4.8\% test error), exceeding the accuracy of human raters.},
	journaltitle = {{arXiv}:1502.03167 [cs]},
	author = {Ioffe, Sergey and Szegedy, Christian},
	urldate = {2020-02-28},
	date = {2015-03-02},
	eprinttype = {arxiv},
	eprint = {1502.03167},
	keywords = {Computer Science - Machine Learning},
	annotation = { Cited by 16258}
}

@online{bishop_pattern_2006,
	title = {Pattern recognition and machine learning},
	url = {https://cds.cern.ch/record/998831},
	abstract = {This is the first textbook on pattern recognition to present the Bayesian viewpoint. The book presents approximate inference algorithms that permit fast approximate answers in situations where exact answers are not feasible. It uses graphical models to describe probability distributions when no other books apply graphical models to machine learning. No previous knowledge of pattern recognition or machine learning concepts is assumed. Familiarity with multivariate calculus and basic linear algebra is required, and some experience in the use of probabilities would be helpful though not essential as the book includes a self-contained introduction to basic probability theory.},
	titleaddon = {{CERN} Document Server},
	author = {Bishop, Christopher M.},
	urldate = {2020-02-28},
	date = {2006},
	langid = {english},
	annotation = {Cited by 41367}
}

@article{cunefare_open_2017,
	title = {Open source software for automatic detection of cone photoreceptors in adaptive optics ophthalmoscopy using convolutional neural networks},
	volume = {7},
	rights = {2017 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-017-07103-0},
	doi = {10.1038/s41598-017-07103-0},
	abstract = {Imaging with an adaptive optics scanning light ophthalmoscope ({AOSLO}) enables direct visualization of the cone photoreceptor mosaic in the living human retina. Quantitative analysis of {AOSLO} images typically requires manual grading, which is time consuming, and subjective; thus, automated algorithms are highly desirable. Previously developed automated methods are often reliant on ad hoc rules that may not be transferable between different imaging modalities or retinal locations. In this work, we present a convolutional neural network ({CNN}) based method for cone detection that learns features of interest directly from training data. This cone-identifying algorithm was trained and validated on separate data sets of confocal and split detector {AOSLO} images with results showing performance that closely mimics the gold standard manual process. Further, without any need for algorithmic modifications for a specific {AOSLO} imaging system, our fully-automated multi-modality {CNN}-based cone detection method resulted in comparable results to previous automatic cone  methods which utilized ad hoc rules for different applications. We have made free open-source software for the proposed method and the corresponding training and testing datasets available online.},
	pages = {1--11},
	number = {1},
	journaltitle = {Scientific Reports},
	author = {Cunefare, David and Fang, Leyuan and Cooper, Robert F. and Dubra, Alfredo and Carroll, Joseph and Farsiu, Sina},
	urldate = {2020-02-28},
	date = {2017-07-26},
	langid = {english},
	annotation = {https://github.com/{DavidCunefare}/{CNN}-Cone-Detection},
}

@book{Goodfellow-et-al-2016,
	title={Deep Learning},
	author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
	publisher={MIT Press},
	note={\url{http://www.deeplearningbook.org}},
	year={2016}
}

@article{fang,
	title = {Automatic segmentation of nine retinal layer boundaries in {OCT} images of non-exudative {AMD} patients using deep learning and graph search},
	volume = {8},
	rights = {\&\#169; 2017 Optical Society of America},
	issn = {2156-7085},
	url = {https://www.osapublishing.org/boe/abstract.cfm?uri=boe-8-5-2732},
	doi = {10.1364/BOE.8.002732},
	abstract = {We present a novel framework combining convolutional neural networks ({CNN}) and graph search methods (termed as {CNN}-{GS}) for the automatic segmentation of nine layer boundaries on retinal optical coherence tomography ({OCT}) images. {CNN}-{GS} first utilizes a {CNN} to extract features of specific retinal layer boundaries and train a corresponding classifier to delineate a pilot estimate of the eight layers. Next, a graph search method uses the probability maps created from the {CNN} to find the final boundaries. We validated our proposed method on 60 volumes (2915 B-scans) from 20 human eyes with non-exudative age-related macular degeneration ({AMD}), which attested to effectiveness of our proposed technique.},
	pages = {2732--2744},
	number = {5},
	journaltitle = {Biomedical Optics Express},
	shortjournal = {Biomed. Opt. Express, {BOE}},
	author = {Fang, Leyuan and Cunefare, David and Wang, Chong and Guymer, Robyn H. and Li, Shutao and Farsiu, Sina},
	urldate = {2020-04-26},
	date = {2017-05-01},
	note = {Publisher: Optical Society of America},
	keywords = {Image analysis, Machine vision, Neural networks, Ophthalmic imaging, Optical coherence tomography, Retinal nerve fiber layer}
}


@article{ting_artificial_2019,
	title = {Artificial intelligence and deep learning in ophthalmology},
	volume = {103},
	rights = {© Author(s) (or their employer(s)) 2019. Re-use permitted under {CC} {BY}-{NC}. No commercial re-use. See rights and permissions. Published by {BMJ}..  This is an open access article distributed in accordance with the Creative Commons Attribution Non Commercial ({CC} {BY}-{NC} 4.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited, appropriate credit is given, any changes made indicated, and the use is non-commercial. See: http://creativecommons.org/licenses/by-nc/4.0},
	issn = {0007-1161, 1468-2079},
	url = {https://bjo.bmj.com/content/103/2/167},
	doi = {10.1136/bjophthalmol-2018-313173},
	abstract = {Artificial intelligence ({AI}) based on deep learning ({DL}) has sparked tremendous global interest in recent years. {DL} has been widely adopted in image recognition, speech recognition and natural language processing, but is only beginning to impact on healthcare. In ophthalmology, {DL} has been applied to fundus photographs, optical coherence tomography and visual fields, achieving robust classification performance in the detection of diabetic retinopathy and retinopathy of prematurity, the glaucoma-like disc, macular oedema and age-related macular degeneration. {DL} in ocular imaging may be used in conjunction with telemedicine as a possible solution to screen, diagnose and monitor major eye diseases for patients in primary care and community settings. Nonetheless, there are also potential challenges with {DL} application in ophthalmology, including clinical and technical challenges, explainability of the algorithm results, medicolegal issues, and physician and patient acceptance of the {AI} ‘black-box’ algorithms. {DL} could potentially revolutionise how ophthalmology is practised in the future. This review provides a summary of the state-of-the-art {DL} systems described for ophthalmic applications, potential challenges in clinical deployment and the path forward.},
	pages = {167--175},
	number = {2},
	journaltitle = {British Journal of Ophthalmology},
	author = {Ting, Daniel Shu Wei and Pasquale, Louis R. and Peng, Lily and Campbell, John Peter and Lee, Aaron Y. and Raman, Rajiv and Tan, Gavin Siew Wei and Schmetterer, Leopold and Keane, Pearse A. and Wong, Tien Yin},
	urldate = {2020-02-28},
	date = {2019-02-01},
	langid = {english},
	pmid = {30361278},
	keywords = {glaucoma, imaging, public health, retina, telemedicine},
	annotation = {Cited by 77
 }
}

@article{cunefare_deep_2018,
	title = {Deep learning based detection of cone photoreceptors with multimodal adaptive optics scanning light ophthalmoscope images of achromatopsia},
	volume = {9},
	rights = {\&\#169; 2018 Optical Society of America},
	issn = {2156-7085},
	url = {https://www.osapublishing.org/boe/abstract.cfm?uri=boe-9-8-3740},
	doi = {10.1364/BOE.9.003740},
	abstract = {Fast and reliable quantification of cone photoreceptors is a bottleneck in the clinical utilization of adaptive optics scanning light ophthalmoscope ({AOSLO}) systems for the study, diagnosis, and prognosis of retinal diseases. To-date, manual grading has been the sole reliable source of {AOSLO} quantification, as no automatic method has been reliably utilized for cone detection in real-world low-quality images of diseased retina. We present a novel deep learning based approach that combines information from both the confocal and non-confocal split detector {AOSLO} modalities to detect cones in subjects with achromatopsia. Our dual-mode deep learning based approach outperforms the state-of-the-art automated techniques and is on a par with human grading.},
	pages = {3740--3756},
	number = {8},
	journaltitle = {Biomedical Optics Express},
	shortjournal = {Biomed. Opt. Express, {BOE}},
	author = {Cunefare, David and Langlo, Christopher S. and Patterson, Emily J. and Blau, Sarah and Dubra, Alfredo and Carroll, Joseph and Farsiu, Sina},
	urldate = {2020-02-28},
	date = {2018-08-01},
	keywords = {Cone cells, Image processing, Optical coherence tomography, Photoreceptors, Stochastic gradient descent, Visual acuity}
}

@article{ronneberger_u-net_2015,
	title = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
	url = {http://arxiv.org/abs/1505.04597},
	shorttitle = {U-Net},
	abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the {ISBI} challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and {DIC}) we won the {ISBI} cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent {GPU}. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
	journaltitle = {{arXiv}:1505.04597 [cs]},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	urldate = {2020-03-27},
	date = {2015-05-18},
	eprinttype = {arxiv},
	eprint = {1505.04597},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annotation = {Comment: conditionally accepted at {MICCAI} 2015}
}

@incollection{ciresan_deep_2012,
	title = {Deep Neural Networks Segment Neuronal Membranes in Electron Microscopy Images},
	url = {http://papers.nips.cc/paper/4741-deep-neural-networks-segment-neuronal-membranes-in-electron-microscopy-images.pdf},
	pages = {2843--2851},
	booktitle = {Advances in Neural Information Processing Systems 25},
	publisher = {Curran Associates, Inc.},
	author = {Ciresan, Dan and Giusti, Alessandro and Gambardella, Luca M. and Schmidhuber, Jürgen},
	editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
	urldate = {2020-03-28},
	date = {2012}
}

@article{falk_u-net_2019,
	title = {U-Net: deep learning for cell counting, detection, and morphometry},
	volume = {16},
	rights = {2018 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/s41592-018-0261-2},
	doi = {10.1038/s41592-018-0261-2},
	shorttitle = {U-Net},
	abstract = {A user-friendly {ImageJ} plugin enables the application and training of U-Nets for deep-learning-based image segmentation, detection and classification tasks with minimal labeling requirements.},
	pages = {67--70},
	number = {1},
	journaltitle = {Nature Methods},
	author = {Falk, Thorsten and Mai, Dominic and Bensch, Robert and Çiçek, Özgün and Abdulkadir, Ahmed and Marrakchi, Yassine and Böhm, Anton and Deubner, Jan and Jäckel, Zoe and Seiwald, Katharina and Dovzhenko, Alexander and Tietz, Olaf and Dal Bosco, Cristina and Walsh, Sean and Saltukoglu, Deniz and Tay, Tuan Leng and Prinz, Marco and Palme, Klaus and Simons, Matias and Diester, Ilka and Brox, Thomas and Ronneberger, Olaf},
	urldate = {2020-03-28},
	date = {2019-01},
	langid = {english},
	note = {Number: 1
Publisher: Nature Publishing Group}
}

@inproceedings{long_fully_2015,
	title = {Fully Convolutional Networks for Semantic Segmentation},
	url = {https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Long_Fully_Convolutional_Networks_2015_CVPR_paper.html},
	eventtitle = {Proceedings of the {IEEE} Conference on Computer Vision and Pattern Recognition},
	pages = {3431--3440},
	author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
	urldate = {2020-03-28},
	date = {2015}
}

@online{noauthor_notitle_nodate,
	url = {https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf},
	urldate = {2020-03-28}
}

@online{noauthor_notitle_nodate-1,
	url = {https://journals.plos.org/plosone/article/file?type=printable&id=10.1371/journal.pone.0218918},
	urldate = {2020-03-30}
}

@article{patton_retinal_2005,
	title = {Retinal vascular image analysis as a potential screening tool for cerebrovascular disease: a rationale based on homology between cerebral and retinal microvasculatures},
	volume = {206},
	issn = {0021-8782},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1571489/},
	doi = {10.1111/j.1469-7580.2005.00395.x},
	shorttitle = {Retinal vascular image analysis as a potential screening tool for cerebrovascular disease},
	abstract = {The retinal and cerebral microvasculatures share many morphological and physiological properties. Assessment of the cerebral microvasculature requires highly specialized and expensive techniques. The potential for using non-invasive clinical assessment of the retinal microvasculature as a marker of the state of the cerebrovasculature offers clear advantages, owing to the ease with which the retinal vasculature can be directly visualized in vivo and photographed due to its essential two-dimensional nature. The use of retinal digital image analysis is becoming increasingly common, and offers new techniques to analyse different aspects of retinal vascular topography, including retinal vascular widths, geometrical attributes at vessel bifurcations and vessel tracking. Being predominantly automated and objective, these techniques offer an exciting opportunity to study the potential to identify retinal microvascular abnormalities as markers of cerebrovascular pathology. In this review, we describe the anatomical and physiological homology between the retinal and cerebral microvasculatures. We review the evidence that retinal microvascular changes occur in cerebrovascular disease and review current retinal image analysis tools that may allow us to use different aspects of the retinal microvasculature as potential markers for the state of the cerebral microvasculature.},
	pages = {319--348},
	number = {4},
	journaltitle = {Journal of Anatomy},
	shortjournal = {J Anat},
	author = {Patton, Niall and Aslam, Tariq and {MacGillivray}, Thomas and Pattie, Alison and Deary, Ian J and Dhillon, Baljean},
	urldate = {2020-03-30},
	date = {2005-04},
	pmid = {15817102},
	pmcid = {PMC1571489}
}

@article{burns_adaptive_2019,
	title = {Adaptive optics imaging of the human retina},
	volume = {68},
	issn = {1350-9462},
	url = {http://www.sciencedirect.com/science/article/pii/S1350946218300405},
	doi = {10.1016/j.preteyeres.2018.08.002},
	abstract = {Adaptive Optics ({AO}) retinal imaging has provided revolutionary tools to scientists and clinicians for studying retinal structure and function in the living eye. From animal models to clinical patients, {AO} imaging is changing the way scientists are approaching the study of the retina. By providing cellular and subcellular details without the need for histology, it is now possible to perform large scale studies as well as to understand how an individual retina changes over time. Because {AO} retinal imaging is non-invasive and when performed with near-{IR} wavelengths both safe and easily tolerated by patients, it holds promise for being incorporated into clinical trials providing cell specific approaches to monitoring diseases and therapeutic interventions. {AO} is being used to enhance the ability of {OCT}, fluorescence imaging, and reflectance imaging. By incorporating imaging that is sensitive to differences in the scattering properties of retinal tissue, it is especially sensitive to disease, which can drastically impact retinal tissue properties. This review examines human {AO} retinal imaging with a concentration on the use of the Adaptive Optics Scanning Laser Ophthalmoscope ({AOSLO}). It first covers the background and the overall approaches to human {AO} retinal imaging, and the technology involved, and then concentrates on using {AO} retinal imaging to study the structure and function of the retina.},
	pages = {1--30},
	journaltitle = {Progress in Retinal and Eye Research},
	shortjournal = {Progress in Retinal and Eye Research},
	author = {Burns, Stephen A. and Elsner, Ann E. and Sapoznik, Kaitlyn A. and Warner, Raymond L. and Gast, Thomas J.},
	urldate = {2020-03-30},
	date = {2019-01-01},
	langid = {english},
	keywords = {Photoreceptors, Blood flow, Imaging, Ophthalmoscopy, Retina, Retinal degenerations, Vascular disease}
}

@article{chui_use_2012,
	title = {The use of forward scatter to improve retinal vascular imaging with an adaptive optics scanning laser ophthalmoscope},
	volume = {3},
	rights = {\&\#169; 2012 {OSA}},
	issn = {2156-7085},
	url = {https://www.osapublishing.org/boe/abstract.cfm?uri=boe-3-10-2537},
	doi = {10.1364/BOE.3.002537},
	abstract = {Retinal vascular diseases are a leading cause of blindness and visual disability. The advent of adaptive optics retinal imaging has enabled us to image the retinal vascular at cellular resolutions, but imaging of the vasculature can be difficult due to the complex nature of the images, including features of many other retinal structures, such as the nerve fiber layer, glial and other cells. In this paper we show that varying the size and centration of the confocal aperture of an adaptive optics scanning laser ophthalmoscope ({AOSLO}) can increase sensitivity to multiply scattered light, especially light forward scattered from the vasculature and erythrocytes. The resulting technique was tested by imaging regions with different retinal tissue reflectivities as well as within the optic nerve head.},
	pages = {2537--2549},
	number = {10},
	journaltitle = {Biomedical Optics Express},
	shortjournal = {Biomed. Opt. Express, {BOE}},
	author = {Chui, Toco Y. P. and {VanNasdale}, Dean A. and Burns, Stephen A.},
	urldate = {2020-03-30},
	date = {2012-10-01},
	note = {Publisher: Optical Society of America},
	keywords = {Image processing, Visual acuity, Imaging systems, Imaging techniques, Optic nerve, Wave front sensing}
}

@article{castro_rapid_2016,
	title = {Rapid high resolution imaging with a dual-channel scanning technique},
	volume = {41},
	rights = {\&\#169; 2016 Optical Society of America},
	issn = {1539-4794},
	url = {https://www.osapublishing.org/ol/abstract.cfm?uri=ol-41-8-1881},
	doi = {10.1364/OL.41.001881},
	abstract = {A spatial shift between channels in a dual-beam raster-scan imaging system introduces a temporal separation between images from the two channels that can be much shorter than the frame rate of the system. The technique is demonstrated by measuring the velocity of erythrocytes in the retinal capillaries. We used an adaptive optics scanning laser ophthalmoscope and introduced a temporal separation between imaging channels of 4.7 ms. We imaged three subjects and measured changing capillary blood flow velocity at the pulse rate. Since the time shift between channels is easily and continuously adjustable, this method can be used to measure rapidly changing events in any raster scan system with little added complexity.},
	pages = {1881--1884},
	number = {8},
	journaltitle = {Optics Letters},
	shortjournal = {Opt. Lett., {OL}},
	author = {Castro, Alberto de and Huang, Gang and Sawides, Lucie and Luo, Ting and Burns, Stephen A.},
	urldate = {2020-03-30},
	date = {2016-04-15},
	note = {Publisher: Optical Society of America},
	keywords = {Optical coherence tomography, Imaging systems, Imaging techniques, Eye movements, Image registration, Real time imaging}
}

@inproceedings{raina_large-scale_2009,
	location = {Montreal, Quebec, Canada},
	title = {Large-scale deep unsupervised learning using graphics processors},
	isbn = {978-1-60558-516-1},
	url = {https://doi.org/10.1145/1553374.1553486},
	doi = {10.1145/1553374.1553486},
	series = {{ICML} '09},
	abstract = {The promise of unsupervised learning methods lies in their potential to use vast amounts of unlabeled data to learn complex, highly nonlinear models with millions of free parameters. We consider two well-known unsupervised learning models, deep belief networks ({DBNs}) and sparse coding, that have recently been applied to a flurry of machine learning applications (Hinton \& Salakhutdinov, 2006; Raina et al., 2007). Unfortunately, current learning algorithms for both models are too slow for large-scale applications, forcing researchers to focus on smaller-scale models, or to use fewer training examples. In this paper, we suggest massively parallel methods to help resolve these problems. We argue that modern graphics processors far surpass the computational capabilities of multicore {CPUs}, and have the potential to revolutionize the applicability of deep unsupervised learning methods. We develop general principles for massively parallelizing unsupervised learning tasks using graphics processors. We show that these principles can be applied to successfully scaling up learning algorithms for both {DBNs} and sparse coding. Our implementation of {DBN} learning is up to 70 times faster than a dual-core {CPU} implementation for large models. For example, we are able to reduce the time required to learn a four-layer {DBN} with 100 million free parameters from several weeks to around a single day. For sparse coding, we develop a simple, inherently parallel algorithm, that leads to a 5 to 15-fold speedup over previous methods.},
	pages = {873--880},
	booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
	publisher = {Association for Computing Machinery},
	author = {Raina, Rajat and Madhavan, Anand and Ng, Andrew Y.},
	urldate = {2020-03-29},
	date = {2009-06-14}
}

@article{martin_pulsatility_2009,
	title = {Pulsatility of parafoveal capillary leukocytes},
	volume = {88},
	issn = {0014-4835},
	url = {http://www.sciencedirect.com/science/article/pii/S0014483508002066},
	doi = {10.1016/j.exer.2008.07.008},
	abstract = {The use of adaptive optics ({AO}) in a confocal scanning laser ophthalmoscope ({AOSLO}) allows for long-term imaging of parafoveal capillary leukocyte movement and measurement of leukocyte velocity without contrast dyes. We applied the {AOSLO} to investigate the possible role of the cardiac cycle on capillary leukocyte velocity by directly measuring capillary leukocyte pulsatility. The parafoveal regions of 8 eight normal healthy subjects with clear ocular media were imaged with an {AOSLO}. All subjects were dilated and cyclopleged. The {AOSLO} field of view was either 1.4×1.5 degrees or 2.35×2.5 degrees, the imaging wavelength was 532nm and the frame rate was 30fps. A photoplethysmograph was used to record the subject's pulse synchronously with each {AOSLO} video. Parafoveal capillary leukocyte velocities and pulsatility were determined for two or three capillaries per subject. Leukocyte velocity and pulsatility were determined for all eight subjects. The mean parafoveal capillary leukocyte velocity for all subjects was Vmean=1.30mm/s ({SD}=±0.40mm/s). There was a statistically significant difference between leukocyte velocities, Vmax and Vmin, over the pulse cycle for each subject (p{\textless}0.05). The mean pulsatility was Pmean=0.45 (±0.09). Parafoveal capillary leukocyte pulsatility can be directly and non-invasively measured without the use of contrast dyes using an {AOSLO}. A substantial amount of the variation found in leukocyte velocity is due to the pulsatility that is induced by the cardiac cycle. By controlling for the variation in leukocyte velocity caused by the cardiac cycle, we can better detect other changes in retinal leukocyte velocity induced by disease or pharmaceutical agents.},
	pages = {356--360},
	number = {3},
	journaltitle = {Experimental Eye Research},
	shortjournal = {Experimental Eye Research},
	author = {Martin, Joy A. and Roorda, Austin},
	urldate = {2020-04-25},
	date = {2009-03-01},
	langid = {english},
	keywords = {adaptive optics, blood flow, pulsatility, scanning laser ophthalmoscope}
}

@article{martin_direct_2005,
	title = {Direct and Noninvasive Assessment of Parafoveal Capillary Leukocyte Velocity},
	volume = {112},
	issn = {0161-6420},
	url = {http://www.sciencedirect.com/science/article/pii/S0161642005009115},
	doi = {10.1016/j.ophtha.2005.06.033},
	abstract = {Purpose
	Alterations in leukocyte velocity have been implicated in many retinal disease processes. However, direct and objective assessment of leukocyte velocity in retinal capillaries has been limited by a reliance on invasive contrast dyes that allow leukocyte visualization only for a short time span. The recent application of adaptive optics in a scanning laser ophthalmoscope ({AOSLO}) has made long-term imaging of parafoveal leukocyte movement possible without contrast dyes. In this study, using the {AOSLO}, we demonstrate a new method to investigate retinal parafoveal capillary leukocyte velocity.
	Design
	Experimental study.
	Participants
	Six normal healthy subjects ranging from 25 to 35 years of age with clear ocular media.
	Methods
	The parafoveal zone of the retina was imaged in all subjects using an {AOSLO}.
	Main Outcome Measures
	Leukocyte velocity was determined in the parafoveal capillaries including the foveal avascular zone border. Leukocyte velocity was measured directly from movie segments in which the leukocytes were clearly visible.
	Results
	The mean parafoveal leukocyte velocity for 6 subjects was 1.37 mm/second, ranging from 0.77 to 2.10 mm/second. Leukocytes were not visible in all parafoveal capillaries.
	Conclusions
	Parafoveal capillary leukocyte velocity can be directly and noninvasively measured without the use of contrast dyes using an {AOSLO}.},
	pages = {2219--2224},
	number = {12},
	journaltitle = {Ophthalmology},
	shortjournal = {Ophthalmology},
	author = {Martin, Joy A. and Roorda, Austin},
	urldate = {2020-04-25},
	date = {2005-12-01},
	langid = {english}
}

@article{ciresan_deep_2010,
	title = {Deep, Big, Simple Neural Nets for Handwritten Digit Recognition},
	volume = {22},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/NECO_a_00052},
	doi = {10.1162/NECO_a_00052},
	abstract = {Good old online backpropagation for plain multilayer perceptrons yields a very low 0.35\% error rate on the {MNIST} handwritten digits benchmark. All we need to achieve this best result so far are many hidden layers, many neurons per layer, numerous deformed training images to avoid overfitting, and graphics cards to greatly speed up learning.},
	pages = {3207--3220},
	number = {12},
	journaltitle = {Neural Computation},
	shortjournal = {Neural Computation},
	author = {Cireşan, Dan Claudiu and Meier, Ueli and Gambardella, Luca Maria and Schmidhuber, Jürgen},
	urldate = {2020-03-30},
	date = {2010-09-21},
	note = {Publisher: {MIT} Press}
}

@inproceedings{he_deep_2016,
	title = {Deep Residual Learning for Image Recognition},
	booktitle = {The {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	date = {2016-06}
}

@inproceedings{deng_imagenet_2009,
	title = {{ImageNet}: A large-scale hierarchical image database},
	doi = {10.1109/CVPR.2009.5206848},
	shorttitle = {{ImageNet}},
	abstract = {The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called “{ImageNet}”, a large-scale ontology of images built upon the backbone of the {WordNet} structure. {ImageNet} aims to populate the majority of the 80,000 synsets of {WordNet} with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of {WordNet}. This paper offers a detailed analysis of {ImageNet} in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that {ImageNet} is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of {ImageNet} through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of {ImageNet} can offer unparalleled opportunities to researchers in the computer vision community and beyond.},
	eventtitle = {2009 {IEEE} Conference on Computer Vision and Pattern Recognition},
	pages = {248--255},
	booktitle = {2009 {IEEE} Conference on Computer Vision and Pattern Recognition},
	author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
	date = {2009-06},
	note = {{ISSN}: 1063-6919},
	keywords = {computer vision, Explosions, Image databases, image resolution, image retrieval, Image retrieval, {ImageNet} database, Information retrieval, Internet, large-scale hierarchical image database, large-scale ontology, Large-scale systems, multimedia computing, multimedia data, Multimedia databases, Ontologies, ontologies (artificial intelligence), Robustness, Spine, subtree, trees (mathematics), very large databases, visual databases, {wordNet} structure}
}

@inproceedings{dubra_registration_2010,
	location = {Berlin, Heidelberg},
	title = {Registration of 2D Images from Fast Scanning Ophthalmic Instruments},
	isbn = {978-3-642-14366-3},
	doi = {10.1007/978-3-642-14366-3_6},
	series = {Lecture Notes in Computer Science},
	abstract = {Images from high-resolution scanning ophthalmic instruments are significantly distorted due to eye movement. Accurate image registration is required to successfully image subjects who are unable to fixate due to retinal conditions. Moreover, all scanning ophthalmic imaging modalities using adaptive optics will benefit from image registration, even in subjects with good fixation and anaesthetized animals. Transformation functions used to map two images could in principle be very complex. Here, we show that when the scanning in ophthalmic instruments is sufficiently fast with respect to the speed of involuntary eye movement, these mapping functions become the addition of a linear term and a single variable function. Then, based on experimental data on eye movement amplitude and speed of the fixating eye, minimum sampling frequencies for these instruments are discussed. Finally, a simple method for estimating the image transformation functions by taking advantage of the finite bandwidth of the motion signals is presented.},
	pages = {60--71},
	booktitle = {Biomedical Image Registration},
	publisher = {Springer},
	author = {Dubra, Alfredo and Harvey, Zachary},
	editor = {Fischer, Bernd and Dawant, Benoît M. and Lorenz, Cristian},
	date = {2010},
	langid = {english},
	keywords = {Current Frame, Discrete Cosine Transform, Discrete Fourier Transform, Optical Coherence Tomography, Retinal Pigment Epithelial Cell}
}


@misc{yilmaz_object_2006,
	title = {Object tracking: A survey},
	url = {https://doi.org/10.1145/1177352.1177355},
	shorttitle = {Object tracking},
	abstract = {The goal of this article is to review the state-of-the-art tracking methods, classify them into different categories, and identify new trends. Object tracking, in general, is a challenging problem. Difficulties in tracking objects can arise due to abrupt object motion, changing appearance patterns of both the object and the scene, nonrigid object structures, object-to-object and object-to-scene occlusions, and camera motion. Tracking is usually performed in the context of higher-level applications that require the location and/or shape of the object in every frame. Typically, assumptions are made to constrain the tracking problem in the context of a particular application. In this survey, we categorize the tracking methods on the basis of the object and motion representations used, provide detailed descriptions of representative methods in each category, and examine their pros and cons. Moreover, we discuss the important issues related to tracking including the use of appropriate image features, selection of motion models, and detection of objects.},
	publisher = {Association for Computing Machinery},
	author = {Yilmaz, Alper and Javed, Omar and Shah, Mubarak},
	urldate = {2020-03-30},
	date = {2006-12-25},
	keywords = {Appearance models, contour evolution, feature selection, object detection, object representation, point tracking, shape tracking}
}

@article{riva_laser_1972,
	title = {Laser Doppler Measurements of Blood Flow in Capillary Tubes and Retinal Arteries},
	volume = {11},
	issn = {1552-5783},
	url = {https://iovs.arvojournals.org/article.aspx?articleid=2122295},
	pages = {936--944},
	number = {11},
	journaltitle = {Investigative Ophthalmology \& Visual Science},
	shortjournal = {Invest. Ophthalmol. Vis. Sci.},
	author = {Riva, Charles and Ross, Benjamin and Benedek, George B.},
	urldate = {2020-04-23},
	date = {1972-11-01},
	langid = {english},
	note = {Publisher: The Association for Research in Vision and Ophthalmology}
}

@article{tam_noninvasive_2010,
	title = {Noninvasive Visualization and Analysis of Parafoveal Capillaries in Humans},
	volume = {51},
	issn = {1552-5783},
	url = {https://iovs.arvojournals.org/article.aspx?articleid=2165417},
	doi = {10.1167/iovs.09-4483},
	pages = {1691--1698},
	number = {3},
	journaltitle = {Investigative Ophthalmology \& Visual Science},
	shortjournal = {Invest. Ophthalmol. Vis. Sci.},
	author = {Tam, Johnny and Martin, Joy A. and Roorda, Austin},
	urldate = {2020-04-24},
	date = {2010-03-01},
	langid = {english},
	note = {Publisher: The Association for Research in Vision and Ophthalmology},
	annotation = {Cited by 192
 }
}

@article{tam_speed_2011,
	title = {Speed quantification and tracking of moving objects in adaptive optics scanning laser ophthalmoscopy},
	volume = {16},
	issn = {1083-3668, 1560-2281},
	url = {https://www.spiedigitallibrary.org/journals/Journal-of-Biomedical-Optics/volume-16/issue-3/036002/Speed-quantification-and-tracking-of-moving-objects-in-adaptive-optics/10.1117/1.3548880.short},
	doi = {10.1117/1.3548880},
	abstract = {Microscopic features of the human retina can be resolved noninvasively using an adaptive optics scanning laser ophthalmoscope ({AOSLO}). We describe an improved method to track and quantify the speed of moving objects in {AOSLO} videos, which is necessary for characterizing the hemodynamics of retinal capillaries. During video acquisition, the objects of interest are in constant motion relative to the background tissue (object motion). The background tissue is in constant motion relative to the {AOSLO}, due to continuous eye motion during video recordings (eye motion). The location at which {AOSLO} acquires data is also in continuous motion, since the imaging source is swept in a raster scan across the retina (raster scanning). We show that it is important to take into consideration the combination of object motion, eye motion, and raster scanning for accurate quantification of object speeds. The proposed methods performed well on both experimental {AOSLO} videos as well as synthetic videos generated by a virtual {AOSLO}. These methods improve the accuracy of methods to investigate hemodynamics using {AOSLO} imaging.},
	pages = {036002},
	number = {3},
	journaltitle = {Journal of Biomedical Optics},
	shortjournal = {{JBO}},
	author = {Tam, Johnny and Roorda, Austin},
	urldate = {2020-04-25},
	date = {2011-03},
	note = {Publisher: International Society for Optics and Photonics}
}

@article{tam_characterization_2011,
	title = {Characterization of single-file flow through human retinal parafoveal capillaries using an adaptive optics scanning laser ophthalmoscope},
	volume = {2},
	rights = {\&\#169; 2011 {OSA}},
	issn = {2156-7085},
	url = {https://www.osapublishing.org/boe/abstract.cfm?uri=boe-2-4-781},
	doi = {10.1364/BOE.2.000781},
	abstract = {Adaptive Optics Scanning Laser Ophthalmoscopy was used to noninvasively acquire videos of single-file flow through live human retinal parafoveal capillaries. Videos were analyzed offline to investigate capillary flow dynamics. Certain capillaries accounted for a clear majority of leukocyte traffic (Leukocyte-Preferred-Paths, {LPPs}), while other capillaries primarily featured plasma gap flow (Plasma-Gap-Capillaries, {PGCs}). {LPPs} may serve as a protective mechanism to prevent inactivated leukocytes from entering exchange capillaries, and {PGCs} may serve as relief valves to minimize flow disruption due to the presence of a leukocyte in a neighboring {LPP}.},
	pages = {781--793},
	number = {4},
	journaltitle = {Biomedical Optics Express},
	shortjournal = {Biomed. Opt. Express, {BOE}},
	author = {Tam, Johnny and Tiruveedhula, Pavan and Roorda, Austin},
	urldate = {2020-04-24},
	date = {2011-04-01},
	note = {Publisher: Optical Society of America},
	keywords = {Adaptive optics, Analytical techniques, Imaging techniques, Network topology, Scanning laser ophthalmoscopy, Spatial resolution},
	annotation = {Cited By 95
 }
}

@article{mizutani_accelerated_diabetes_1996,
	title = {Accelerated death of retinal microvascular cells in human and experimental diabetic retinopathy.},
	volume = {97},
	issn = {0021-9738},
	url = {https://www.jci.org/articles/view/118746},
	doi = {10.1172/JCI118746},
	pages = {2883--2890},
	number = {12},
	journaltitle = {The Journal of Clinical Investigation},
	shortjournal = {J Clin Invest},
	author = {Mizutani, M. and Kern, T. S. and Lorenzi, M.},
	urldate = {2020-04-24},
	date = {1996-06-15},
	langid = {english},
	pmid = {8675702},
	note = {Publisher: American Society for Clinical Investigation}
}

@article{zhong_vivo_2008,
	title = {In vivo measurement of erythrocyte velocity and retinal blood flow using adaptive optics scanning laser ophthalmoscopy},
	volume = {16},
	rights = {\&\#169; 2008 Optical Society of America},
	issn = {1094-4087},
	url = {https://www.osapublishing.org/oe/abstract.cfm?uri=oe-16-17-12746},
	doi = {10.1364/OE.16.012746},
	abstract = {In vivo measurement of retinal blood flow is obtained by measuring the blood velocity of erythrocytes and lumen diameters of the blood vessels using an adaptive optics scanning laser ophthalmoscope. Erythrocyte velocity is measured by tracking erythrocytes moving across a horizontal scanning line. This approach provides high temporal bandwidth measurements, allowing the fluctuation of blood flow during cardiac cycles to be measured. The technique is most applicable to medium-sized blood vessels.},
	pages = {12746--12756},
	number = {17},
	journaltitle = {Optics Express},
	shortjournal = {Opt. Express, {OE}},
	author = {Zhong, Zhangyi and Petrig, Benno L. and Qi, Xiaofeng and Burns, Stephen A.},
	urldate = {2020-04-25},
	date = {2008-08-18},
	note = {Publisher: Optical Society of America},
	keywords = {Adaptive optics, Image processing, Infrared radiation, Laser Doppler velocimetry, Near infrared radiation, Wavefront aberrations}
}


@article{bergeles_unsupervised_2017,
	title = {Unsupervised identification of cone photoreceptors in non-confocal adaptive optics scanning light ophthalmoscope images},
	volume = {8},
	rights = {\&\#169; 2017 Optical Society of America},
	issn = {2156-7085},
	url = {https://www.osapublishing.org/boe/abstract.cfm?uri=boe-8-6-3081},
	doi = {10.1364/BOE.8.003081},
	abstract = {Precise measurements of photoreceptor numerosity and spatial arrangement are promising biomarkers for the early detection of retinal pathologies and may be valuable in the evaluation of retinal therapies. Adaptive optics scanning light ophthalmoscopy ({AOSLO}) is a method of imaging that corrects for aberrations of the eye to acquire high-resolution images that reveal the photoreceptor mosaic. These images are typically graded manually by experienced observers, obviating the robust, large-scale use of the technology. This paper addresses unsupervised automated detection of cones in non-confocal, split-detection {AOSLO} images. Our algorithm leverages the appearance of split-detection images to create a cone model that is used for classification. Results show that it compares favorably to the state-of-the-art, both for images of healthy retinas and for images from patients affected by Stargardt disease. The algorithm presented also compares well to manual annotation while excelling in speed.},
	pages = {3081--3094},
	number = {6},
	journaltitle = {Biomedical Optics Express},
	shortjournal = {Biomed. Opt. Express, {BOE}},
	author = {Bergeles, Christos and Dubis, Adam M. and Davidson, Benjamin and Kasilian, Melissa and Kalitzeos, Angelos and Carroll, Joseph and Dubra, Alfredo and Michaelides, Michel and Ourselin, Sebastien},
	urldate = {2020-04-25},
	date = {2017-06-01},
	note = {Publisher: Optical Society of America},
	keywords = {Image analysis, Image processing, Monochromatic aberrations, Photoreceptors, Retina scanning, Scanning laser ophthalmoscopy}
}


@article{ostergaard_role_stroke_2013,
	title = {The Role of the Cerebral Capillaries in Acute Ischemic Stroke: The Extended Penumbra Model},
	volume = {33},
	issn = {0271-678X},
	url = {https://doi.org/10.1038/jcbfm.2013.18},
	doi = {10.1038/jcbfm.2013.18},
	shorttitle = {The Role of the Cerebral Capillaries in Acute Ischemic Stroke},
	abstract = {The pathophysiology of cerebral ischemia is traditionally understood in relation to reductions in cerebral blood flow ({CBF}). However, a recent reanalysis of the flow-diffusion equation shows that increased capillary transit time heterogeneity ({CTTH}) can reduce the oxygen extraction efficacy in brain tissue for a given {CBF}. Changes in capillary morphology are typical of conditions predisposing to stroke and of experimental ischemia. Changes in capillary flow patterns have been observed by direct microscopy in animal models of ischemia and by indirect methods in humans stroke, but their metabolic significance remain unclear. We modeled the effects of progressive increases in {CTTH} on the way in which brain tissue can secure sufficient oxygen to meet its metabolic needs. Our analysis predicts that as {CTTH} increases, {CBF} responses to functional activation and to vasodilators must be suppressed to maintain sufficient tissue oxygenation. Reductions in {CBF}, increases in {CTTH}, and combinations thereof can seemingly trigger a critical lack of oxygen in brain tissue, and the restoration of capillary perfusion patterns therefore appears to be crucial for the restoration of the tissue oxygenation after ischemic episodes. In this review, we discuss the possible implications of these findings for the prevention, diagnosis, and treatment of acute stroke.},
	pages = {635--648},
	number = {5},
	journaltitle = {Journal of Cerebral Blood Flow \& Metabolism},
	shortjournal = {J Cereb Blood Flow Metab},
	author = {Østergaard, Leif and Jespersen, Sune Nørhøj and Mouridsen, Kim and Mikkelsen, Irene Klærke and Jonsdottír, Kristjana Ýr and Tietze, Anna and Blicher, Jakob Udby and Aamand, Rasmus and Hjort, Niels and Iversen, Nina Kerting and Cai, Changsi and Hougaard, Kristina Dupont and Simonsen, Claus Z and Von Weitzel-Mudersbach, Paul and Modrau, Boris and Nagenthiraja, Kartheeban and Ribe, Lars Riisgaard and Hansen, Mikkel Bo and Bekke, Susanne Lise and Dahlman, Martin Gervais and Puig, Josep and Pedraza, Salvador and Serena, Joaquín and Cho, Tae-Hee and Siemonsen, Susanne and Thomalla, Götz and Fiehler, Jens and Nighoghossian, Norbert and Andersen, Grethe},
	urldate = {2020-04-24},
	date = {2013-05-01},
	langid = {english},
	note = {Publisher: {SAGE} Publications Ltd {STM}}
}

@article{wolf_s_quantification_hypertension_1994,
	title = {Quantification of retinal capillary density and flow velocity in patients with essential hypertension.},
	volume = {23},
	url = {https://www.ahajournals.org/doi/abs/10.1161/01.hyp.23.4.464},
	doi = {10.1161/01.HYP.23.4.464},
	abstract = {Arterial hypertension is known to be an important risk factor for cerebral and cardiovascular disease. Previous studies in rats have demonstrated that changes in both capillary density and vessel diameter may contribute to increased vascular resistance in hypertension. In vivo studies of human subjects with essential hypertension revealed a reduction in the number of arterioles in the skin and conjunctiva; no other in vivo data are available from other tissues. By means of a new imaging technique, capillary density and capillary blood flow velocity can now be assessed in the human retina. We undertook the present investigation to determine whether patients with essential hypertension and only minor clinical retinal vascular alterations have decreased retinal capillary density and altered capillary flow velocity. Seventeen hypertensive patients with only minor retinal vascular alterations and 17 healthy volunteers matched for age were selected. All study participants underwent ophthalmologic examination and fluorescein angiographic studies by means of scanning laser ophthalmoscopy. Capillary density and capillary blood flow velocity in the perifoveal network were evaluated from the angiograms. The retinal microcirculation in the perifoveal capillary network of hypertensive patients showed significant alterations. Both the capillary density and capillary flow velocities were significantly reduced compared with the control group. For the first time alterations of capillary blood flow and capillary density in a vascular network very similar to that of the brain have been demonstrated in hypertensive patients in vivo. Further studies with this technique may help identify patients at high risk for cerebrovascular diseases.},
	pages = {464--467},
	number = {4},
	journaltitle = {Hypertension},
	shortjournal = {Hypertension},
	author = {{Wolf S} and {Arend O} and {Schulte K} and {Ittel T H} and {Reim M}},
	urldate = {2020-04-24},
	date = {1994-04-01},
	note = {Publisher: American Heart Association}
}

@article{de_la_torre_is_alzheimer_2004,
	title = {Is Alzheimer's disease a neurodegenerative or a vascular disorder? Data, dogma, and dialectics},
	volume = {3},
	issn = {1474-4422},
	url = {http://www.sciencedirect.com/science/article/pii/S1474442204006830},
	doi = {10.1016/S1474-4422(04)00683-0},
	shorttitle = {Is Alzheimer's disease a neurodegenerative or a vascular disorder?},
	abstract = {The cause of Alzheimer's disease ({AD}) is unknown. This gap in knowledge has created a stumbling block in the search for a genuinely effective treatment or cure for this dementia. This article summarises the arguments for a causal role for either amyloid deposition or cerebrovascular pathology as the primary trigger in the development of non-genetic {AD}. A bare-bones survey of the published research reveals no compelling evidence that amyloid deposition is neurotoxic in human beings or that it results in neurodegenerative changes involving synaptic, metabolic, or neuronal loss in human or transgenic-mouse brains. By contrast, the data supporting {AD} as a primary vascular disorder are more convincing. Findings suggesting a vascular cause of {AD} come from epidemiological, neuroimaging, pathological, pharmacotherapeutic, and clinical studies. The consensus of these studies indicates that chronic brain hypoperfusion is linked to {AD} risk factors, {AD} preclinical detection and pharmacotherapeutic action of {AD} symptoms.},
	pages = {184--190},
	number = {3},
	journaltitle = {The Lancet Neurology},
	shortjournal = {The Lancet Neurology},
	author = {de la Torre, Jack C},
	urldate = {2020-04-24},
	date = {2004-03-01},
	langid = {english}
}


@article{bateman_comparison_multiple_sclerosis_2016,
	title = {A comparison between the pathophysiology of multiple sclerosis and normal pressure hydrocephalus: is pulse wave encephalopathy a component of {MS}?},
	volume = {13},
	issn = {2045-8118},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5034419/},
	doi = {10.1186/s12987-016-0041-2},
	shorttitle = {A comparison between the pathophysiology of multiple sclerosis and normal pressure hydrocephalus},
	abstract = {Background
	It has been suggested there is a chronic neurodegenerative disorder, underlying the pathophysiology of multiple sclerosis ({MS}), which is distinct from the more obvious immune-mediated attack on the white matter. Limited data exists indicating there is an alteration in pulse wave propagation within the craniospinal cavity in {MS}, similar to the findings in normal pressure hydrocephalus ({NPH}). It is hypothesized {MS} may harbor pulse wave encephalopathy. The purpose of this study is to compare blood flow and pulse wave measurements in {MS} patients with a cohort of {NPH} patients and control subjects, to test this hypothesis.
	
	Methods
	Twenty patients with {MS} underwent magnetic resonance ({MR}) flow quantification techniques. Mean blood flow and stroke volume were measured in the arterial inflow and venous out flow from the sagittal ({SSS}) and straight sinus ({ST}). The arteriovenous delay ({AVD}) was defined. The results were compared with both age-matched controls and {NPH} patients.
	
	Results
	In {MS} there was a 35 \% reduction in arteriovenous delay and a 5 \% reduction in the percentage of the arterial inflow returning via the sagittal sinus compared to age matched controls. There was an alteration in pulse wave propagation, with a 26 \% increase in arterial stroke volume but 30 \% reduction in {SSS} and {ST} stroke volume. The {AVD} and blood flow changes were in the same direction to those of {NPH} patients.
	
	Conclusions
	There are blood flow and pulsation propagation changes in {MS} patients which are similar to those of {NPH} patients. The findings would be consistent with an underlying pulse wave encephalopathy component in {MS}.
	
	Electronic supplementary material
	The online version of this article (doi:10.1186/s12987-016-0041-2) contains supplementary material, which is available to authorized users.},
	journaltitle = {Fluids and Barriers of the {CNS}},
	shortjournal = {Fluids Barriers {CNS}},
	author = {Bateman, Grant A. and Lechner-Scott, Jeannette and Lea, Rodney A.},
	urldate = {2020-04-24},
	date = {2016-09-22},
	pmid = {27658732},
	pmcid = {PMC5034419}
}
@article{patton_retinal_brain_vasculature_similarity_2005,
title = {Retinal vascular image analysis as a potential screening tool for cerebrovascular disease: a rationale based on homology between cerebral and retinal microvasculatures},
volume = {206},
issn = {0021-8782},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1571489/},
doi = {10.1111/j.1469-7580.2005.00395.x},
shorttitle = {Retinal vascular image analysis as a potential screening tool for cerebrovascular disease},
abstract = {The retinal and cerebral microvasculatures share many morphological and physiological properties. Assessment of the cerebral microvasculature requires highly specialized and expensive techniques. The potential for using non-invasive clinical assessment of the retinal microvasculature as a marker of the state of the cerebrovasculature offers clear advantages, owing to the ease with which the retinal vasculature can be directly visualized in vivo and photographed due to its essential two-dimensional nature. The use of retinal digital image analysis is becoming increasingly common, and offers new techniques to analyse different aspects of retinal vascular topography, including retinal vascular widths, geometrical attributes at vessel bifurcations and vessel tracking. Being predominantly automated and objective, these techniques offer an exciting opportunity to study the potential to identify retinal microvascular abnormalities as markers of cerebrovascular pathology. In this review, we describe the anatomical and physiological homology between the retinal and cerebral microvasculatures. We review the evidence that retinal microvascular changes occur in cerebrovascular disease and review current retinal image analysis tools that may allow us to use different aspects of the retinal microvasculature as potential markers for the state of the cerebral microvasculature.},
pages = {319--348},
number = {4},
journaltitle = {Journal of Anatomy},
shortjournal = {J Anat},
author = {Patton, Niall and Aslam, Tariq and {MacGillivray}, Thomas and Pattie, Alison and Deary, Ian J and Dhillon, Baljean},
urldate = {2020-03-30},
date = {2005-04},
pmid = {15817102},
pmcid = {PMC1571489}
}
@online{eye_anatomy,
title = {Free Image on Pixabay - Eye, Diagram, Eyeball, Body, Pupil},
url = {https://pixabay.com/vectors/eye-diagram-eyeball-body-pupil-39998/},
abstract = {Download this free picture about Eye Diagram Eyeball from Pixabay's vast library of public domain images and videos.},
urldate = {2020-04-24},
langid = {english},
note = {Library Catalog: pixabay.com}
}

@video{noauthor_varying_nodate,
	title = {Varying focus through retina {AOSLO}},
	url = {https://www.youtube.com/watch?v=xyYidDFWMWQ},
	abstract = {In this video we see an area of 1x1deg 5deg away from the fovea. We start at the photoreceptors and vary the focus moving towards the inner retina. As the focus changes we start seeing blood vessels. These are organised in plexuses that come in and out of view. On the split channel single blood cells are distinguishable. The nerve fibre layer appears as white vertical streaks on the confocal. The caption for inner and outer segments are reversed. The outer segments are seen on the high contrast video, the inner segments on the grayish},
	urldate = {2020-04-24}
}

@article{japee_automated_2005,
	title = {Automated Method for Tracking Individual Red Blood Cells Within Capillaries to Compute Velocity and Oxygen Saturation},
	volume = {12},
	rights = {2005 Blackwell},
	issn = {1549-8719},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1080/10739680591003341},
	doi = {10.1080/10739680591003341},
	abstract = {Objective: The authors present a new method to track individual red blood cells ({RBCs}) as they move through capillaries. This method uses a recently developed Measurement and Analysis System for Capillary Oxygen Transport ({MASCOT}) and the concept of space–time images to track {RBCs} between consecutive frames of video recordings of the microcirculation. Methods: A space–time image displays in a single static image for a single capillary the location of all {RBCs} as a function of time. Analysis is performed on video tapes of {RBC} flow through capillaries to obtain velocity of individual cells as they traverse the capillary of interest. A space–time image is generated to track {RBCs} from one frame to the next and their velocities are computed. Based on the optical density values of each cell obtained from synchronized videotapes at two wavelengths, the oxygen saturation of a cell can be determined. In this manner, oxygen saturation can be tracked for the same cells as they move through the capillary. Results and Conclusions: These measurements, taken together, allow one to determine how much and how fast oxygen is being delivered to the surrounding tissue. This method provides, for the first time, a way to track individual {RBCs} flowing through capillary networks and study their {RBC} dynamics and oxygenation.},
	pages = {507--515},
	number = {6},
	journaltitle = {Microcirculation},
	author = {Japee, Shruti A. and Pittman, Roland N. and Ellis, Christopher G.},
	urldate = {2020-04-24},
	date = {2005},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1080/10739680591003341},
	keywords = {microcirculation, oxygen saturation, red blood cell velocity, tracking}
}


@article{bedggood_direct_2012,
	title = {Direct visualization and characterization of erythrocyte flow in human retinal capillaries},
	volume = {3},
	rights = {\&\#169; 2012 {OSA}},
	issn = {2156-7085},
	url = {https://www.osapublishing.org/boe/abstract.cfm?uri=boe-3-12-3264},
	doi = {10.1364/BOE.3.003264},
	abstract = {Imaging the retinal vasculature offers a surrogate view of systemic vascular health, allowing noninvasive and longitudinal assessment of vascular pathology. The earliest anomalies in vascular disease arise in the microvasculature, however current imaging methods lack the spatiotemporal resolution to track blood flow at the capillary level. We report here on novel imaging technology that allows direct, noninvasive optical imaging of erythrocyte flow in human retinal capillaries. This was made possible using adaptive optics for high spatial resolution (1.5 μm), {sCMOS} camera technology for high temporal resolution (460 fps), and tunable wavebands from a broadband laser for maximal erythrocyte contrast. Particle image velocimetry on our data sequences was used to quantify flow. We observed marked spatiotemporal variability in velocity, which ranged from 0.3 to 3.3 mm/s, and changed by up to a factor of 4 in a given capillary during the 130 ms imaging period. Both mean and standard deviation across the imaged capillary network varied markedly with time, yet their ratio remained a relatively constant parameter (0.50 ± 0.056). Our observations concur with previous work using less direct methods, validating this as an investigative tool for the study of microvascular disease in humans.},
	pages = {3264--3277},
	number = {12},
	journaltitle = {Biomedical Optics Express},
	shortjournal = {Biomed. Opt. Express, {BOE}},
	author = {Bedggood, Phillip and Metha, Andrew},
	urldate = {2020-04-25},
	date = {2012-12-01},
	note = {Publisher: Optical Society of America},
	keywords = {Adaptive optics, Image quality, Imaging techniques, Laser velocimetry, Optical imaging, Speckle imaging}
}

@article{riva_blue_1980,
	title = {Blue field entoptic phenomenon and blood velocity in the retinal capillaries},
	volume = {70},
	rights = {\&\#169; 1980 Optical Society of America},
	url = {https://www.osapublishing.org/josa/abstract.cfm?uri=josa-70-10-1234},
	doi = {10.1364/JOSA.70.001234},
	abstract = {The blue field entoptic phenomenon consists of the perception of one’s own leukocytes (white blood cells) flowing in the macular capillaries of the retina. A method has been developed for determining the speed of the leukocytes. In this method, the motion of the leukocytes is simulated on a screen by means of a minicomputer system. The subject is instructed to match the motion of the simulated white blood cells with that of his own leukocytes. For this, he can adjust the number and the maximum and minimum speeds of the simulated particles. Measurements in five young subjects with normal fundi indicate that the speed of the leukocytes in the macular capillaries of the retina is pulsatile. Minimum and maximum speeds are approximately 0.5 and 1 mm/s.},
	pages = {1234--1238},
	number = {10},
	journaltitle = {{JOSA}},
	shortjournal = {J. Opt. Soc. Am., {JOSA}},
	author = {Riva, C. E. and Petrig, B.},
	urldate = {2020-04-25},
	date = {1980-10-01},
	note = {Publisher: Optical Society of America},
	keywords = {Blood, Cathode ray tubes, Computer simulation, Ophthalmology, Pressure sensors, Retina}
}

@article{grunwald_effect_1993,
	title = {Effect of aging on retinal macular microcirculation: a blue field simulation study.},
	volume = {34},
	issn = {1552-5783},
	url = {https://iovs.arvojournals.org/article.aspx?articleid=2160915},
	shorttitle = {Effect of aging on retinal macular microcirculation},
	pages = {3609--3613},
	number = {13},
	journaltitle = {Investigative Ophthalmology \& Visual Science},
	shortjournal = {Invest. Ophthalmol. Vis. Sci.},
	author = {Grunwald, J. E. and Piltz, J. and Patel, N. and Bose, S. and Riva, C. E.},
	urldate = {2020-04-25},
	date = {1993-12-01},
	langid = {english},
	note = {Publisher: The Association for Research in Vision and Ophthalmology}
}

@article{yang_fluorescent_1997,
	title = {Fluorescent Dots in Fluorescein Angiography and Fluorescein Leukocyte Angiography Using a Scanning Laser Ophthalmoscope in Humans},
	volume = {104},
	issn = {0161-6420},
	url = {http://www.sciencedirect.com/science/article/pii/S0161642097300803},
	doi = {10.1016/S0161-6420(97)30080-3},
	abstract = {Purpose: The purpose of the study is to disclose the nature of fluorescent dots and segments traditionally observed with fluorescein angiography ({FA}) using a scanning laser ophthalmoscope ({SLO} 101; Rodenstock, München, Germany). The authors developed a new method, called fluorescein leukocyte angiography ({FLA}), to display directly the movement of leukocytes in human retinal vessels. Methods: Fluorescein angiography was performed on two normal volunteers using a scanning laser ophthalmoscope and fluorescent dots and segments were observed. Fluorescein leukocyte angiography, using an injection of fluorescent buffy coat layer from which the fluorescent plasma and nonfluorescent erythrocytes have been removed externally, was performed on seven normal volunteers. Injection fluid smears were examined through a fluorescent microscope. Peripheral blood smears taken during midphase of {FA} and {FLA} also were examined. In addition, 15 early-phase {FAs} of central serous chorioretinitis ({CSC}) were studied retrospectively. Results: In the {FAs} of normal volunteers, fluorescent dots were detected only in perimacular capillaries at early phase. Eight of the 15 {CSC} {FAs} examined showed both fluorescent dots and segments. In the {FLAs}, fluorescent dots were detected in whole retinal vessels for more than 30 minutes. Fluorescent segments were observed in {FA} but not in {FLA}. Injected fluid smears from one {FLA} showed fluorescent leukocytes and small platelets. However, in peripheral blood smears of the {FLA}, leukocytes and platelets were more visible and exhibited higher contrast than those of an {FA} due to background plasma fluorescence. The mean velocity of 21 flowing leukocytes in perifoveal capillaries was 1.37 ± 0.35 mm/second in 2 {FAs} and that of 89 flowing leukocytes was 1.41 ± 0.29 mm/second in 7 {FLAs}. Conclusions: The authors' observations suggest that fluorescent dots in scanning laser ophthalmoscope imaging are fluorescein-stained leukocytes, whereas fluorescent segments are the hyperfluorescent plasma that is located between rouleaux formations of erythrocytes. The velocity of the fluorescent dots could be measured in the perimacular capillaries by either {FA} or {FLA}; however, only {FLA} can display the flow of fluorescent leukocytes in large vessels.},
	pages = {1670--1676},
	number = {10},
	journaltitle = {Ophthalmology},
	shortjournal = {Ophthalmology},
	author = {Yang, Yunsik and Kim, Sangduck and Kim, Jaeduck},
	urldate = {2020-04-25},
	date = {1997-10-01},
	langid = {english}
}

@article{paques_evaluation_2000,
	title = {Evaluation of fluorescein-labeled autologous leukocytes for examination of retinal circulation in humans},
	volume = {21},
	issn = {0271-3683},
	url = {https://www.tandfonline.com/doi/abs/10.1076/0271-3683%28200007%292111-ZFT560},
	doi = {10.1076/0271-3683(200007)2111-ZFT560},
	abstract = {Purpose. Increased leukocyte-endothelium interaction have been suggested as a phenomenon contributing to capillary occlusion and/or rupture of the blood-retina barrier during human retinal vascular diseases. This study was performed to evaluate if fluorescein-labeled autologous leukocytes ({FLALs}) can be used for examination of leukocyte transit in the human retina. Methods. The preparation consisted of human dextran-separated leukocytes mixed with fluorescein. After reinjection in normal subjects and in one diabetic patient, a confocal scanning laser ophthalmoscope was used to visualize them in the retinal circulation. The changes between {FLALs} and control leukocytes in the expression of leukocytes adhesion molecules {CD}11b and {CD}62L were evaluated by flow cytometry. Results. The circulating {FLALs} were clearly visible in retinal vessels. The mean (± {SD}) capillaries velocity was 1.43 (± 1.3) mm/s in the macula and 1.82 (± 1.4) mm/s in the peripapillary area. No leukostasis was detected in the normal subjects, while it was detected in te diabetic patient. Flow cytometry revealed an increase in {CD}11b and a decrease in {CD}62L expression of leukocytes after labeling, suggesting that compared to normal leukocytes {FLALs} are more susceptible to interact with vascular endothelium. Conclusions. The use of {FLAL} is presently the only technique applicable in humans for study of leukocyte transit in the retina. Their preparation is technically simple and unexpensive. Precise measurement of the velocity of leukocytes in small vessels can be obtained. Despite evidence of a certain degree of leukocyte activation after the labeling procedure, no leukostasis was detected in vivo in normal subjects. Potential applications for this technique may include the detection of leukostasis in the human retina during severe forms of diabetes and retinal phlebitis.},
	pages = {560--565},
	number = {1},
	journaltitle = {Current Eye Research},
	author = {Paques, M. and Boval, B. and Richard, S. and Tadayoni, R. and Massin, P. and Mundler, O. and Gaudric, A. and Vicaut, E.},
	urldate = {2020-04-25},
	date = {2000-01-01},
	note = {Publisher: Taylor \& Francis
	\_eprint: https://www.tandfonline.com/doi/pdf/10.1076/0271-3683\%28200007\%292111-{ZFT}560}
}

@article{cunefare_automatic_2016,
	title = {Automatic detection of cone photoreceptors in split detector adaptive optics scanning light ophthalmoscope images},
	volume = {7},
	rights = {\&\#169; 2016 Optical Society of America},
	issn = {2156-7085},
	url = {https://www.osapublishing.org/boe/abstract.cfm?uri=boe-7-5-2036},
	doi = {10.1364/BOE.7.002036},
	abstract = {Quantitative analysis of the cone photoreceptor mosaic in the living retina is potentially useful for early diagnosis and prognosis of many ocular diseases. Non-confocal split detector based adaptive optics scanning light ophthalmoscope ({AOSLO}) imaging reveals the cone photoreceptor inner segment mosaics often not visualized on confocal {AOSLO} imaging. Despite recent advances in automated cone segmentation algorithms for confocal {AOSLO} imagery, quantitative analysis of split detector {AOSLO} images is currently a time-consuming manual process. In this paper, we present the fully automatic adaptive filtering and local detection ({AFLD}) method for detecting cones in split detector {AOSLO} images. We validated our algorithm on 80 images from 10 subjects, showing an overall mean Dice\&\#x2019;s coefficient of 0.95 (standard deviation 0.03), when comparing our {AFLD} algorithm to an expert grader. This is comparable to the inter-observer Dice\&\#x2019;s coefficient of 0.94 (standard deviation 0.04). To the best of our knowledge, this is the first validated, fully-automated segmentation method which has been applied to split detector {AOSLO} images.},
	pages = {2036--2050},
	number = {5},
	journaltitle = {Biomedical Optics Express},
	shortjournal = {Biomed. Opt. Express, {BOE}},
	author = {Cunefare, David and Cooper, Robert F. and Higgins, Brian and Katz, David F. and Dubra, Alfredo and Carroll, Joseph and Farsiu, Sina},
	urldate = {2020-04-25},
	date = {2016-05-01},
	note = {Publisher: Optical Society of America},
	keywords = {Clinical applications, Discrete Fourier transforms, Image quality, Imaging systems, Optical coherence tomography, Photoreceptors}
}

@article{cooper_automatic_2013,
	title = {Automatic detection of modal spacing (Yellott's ring) in adaptive optics scanning light ophthalmoscope images},
	volume = {33},
	issn = {1475-1313},
	doi = {10.1111/opo.12070},
	abstract = {{PURPOSE}: An impediment for the clinical utilisation of ophthalmic adaptive optics imaging systems is the automated assessment of photoreceptor mosaic integrity. Here we propose a fully automated algorithm for estimating photoreceptor density based on the radius of Yellott's ring.
	{METHODS}: The discrete Fourier transform ({DFT}) was used to obtain the power spectrum for a series of images of the human photoreceptor mosaic. Cell spacing is estimated by least-square fitting an annular pattern with a Gaussian cross section to the power spectrum; the radius of the resulting annulus provides an estimate of the modal spacing of the photoreceptors in the retinal image. The intrasession repeatability of the cone density estimates from the algorithm was evaluated, and the accuracy of the algorithm was validated against direct count estimates from a previous study. Accuracy in the presence of multiple cell types and disruptions in the mosaic was examined using images from four patients with retinal pathology and perifoveal images from two subjects with normal vision.
	{RESULTS}: Intrasession repeatability of the power spectrum method was comparable to a fully automated direct counting algorithm, but worse than that for the manually adjusted direct count values. In images of the normal parafoveal cone mosaic, we find good agreement between the power-spectrum derived density and that from the direct counting algorithm. In diseased eyes, the power spectrum method is insensitive to photoreceptor loss, with cone density estimates overestimating the density determined with direct counting. The automated power spectrum method also produced unreliable estimates of rod and cone density in perifoveal images of the photoreceptor mosaic, though manual correction of the initial algorithm output results in density estimates in better agreement with direct count values.
	{CONCLUSIONS}: We developed and validated an automated algorithm based on the power spectrum for extracting estimates of cone spacing, from which estimates of density can be derived. This approach may be used to estimate cone density in images where not every single cone is visible, though caution is needed, as this robustness becomes a weakness when dealing with images from patients with some retinal diseases. This study represents an important first step in carefully assessing the relative utility of metrics for analysing the photoreceptor mosaic, and similar analyses of other metrics/algorithms are needed.},
	pages = {540--549},
	number = {4},
	journaltitle = {Ophthalmic \& Physiological Optics: The Journal of the British College of Ophthalmic Opticians (Optometrists)},
	shortjournal = {Ophthalmic Physiol Opt},
	author = {Cooper, Robert F. and Langlo, Christopher S. and Dubra, Alfredo and Carroll, Joseph},
	date = {2013-07},
	pmid = {23668233},
	pmcid = {PMC3690144},
	keywords = {Adult, Algorithms, Cell Count, Color Vision Defects, Female, Humans, Male, Middle Aged, Ophthalmoscopy, Pattern Recognition, Automated, Reproducibility of Results, Retinal Cone Photoreceptor Cells, Retinal Rod Photoreceptor Cells, Retinitis Pigmentosa, Young Adult}
}

@article{perez_effectiveness_2017,
	title = {The Effectiveness of Data Augmentation in Image Classification using Deep Learning},
	url = {http://arxiv.org/abs/1712.04621},
	abstract = {In this paper, we explore and compare multiple solutions to the problem of data augmentation in image classification. Previous work has demonstrated the effectiveness of data augmentation through simple techniques, such as cropping, rotating, and flipping input images. We artificially constrain our access to data to a small subset of the {ImageNet} dataset, and compare each data augmentation technique in turn. One of the more successful data augmentations strategies is the traditional transformations mentioned above. We also experiment with {GANs} to generate images of different styles. Finally, we propose a method to allow a neural net to learn augmentations that best improve the classifier, which we call neural augmentation. We discuss the successes and shortcomings of this method on various datasets.},
	journaltitle = {{arXiv}:1712.04621 [cs]},
	author = {Perez, Luis and Wang, Jason},
	urldate = {2020-03-30},
	date = {2017-12-13},
	eprinttype = {arxiv},
	eprint = {1712.04621},
}


@article{gulshan_development_2016,
	title = {Development and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs},
	volume = {316},
	issn = {0098-7484},
	url = {https://jamanetwork.com/journals/jama/fullarticle/2588763},
	doi = {10.1001/jama.2016.17216},
	abstract = {{\textless}h3{\textgreater}Importance{\textless}/h3{\textgreater}{\textless}p{\textgreater}Deep learning is a family of computational methods that allow an algorithm to program itself by learning from a large set of examples that demonstrate the desired behavior, removing the need to specify rules explicitly. Application of these methods to medical imaging requires further assessment and validation.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Objective{\textless}/h3{\textgreater}{\textless}p{\textgreater}To apply deep learning to create an algorithm for automated detection of diabetic retinopathy and diabetic macular edema in retinal fundus photographs.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Design and Setting{\textless}/h3{\textgreater}{\textless}p{\textgreater}A specific type of neural network optimized for image classification called a deep convolutional neural network was trained using a retrospective development data set of 128 175 retinal images, which were graded 3 to 7 times for diabetic retinopathy, diabetic macular edema, and image gradability by a panel of 54 {US} licensed ophthalmologists and ophthalmology senior residents between May and December 2015. The resultant algorithm was validated in January and February 2016 using 2 separate data sets, both graded by at least 7 {US} board-certified ophthalmologists with high intragrader consistency.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Exposure{\textless}/h3{\textgreater}{\textless}p{\textgreater}Deep learning–trained algorithm.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Main Outcomes and Measures{\textless}/h3{\textgreater}{\textless}p{\textgreater}The sensitivity and specificity of the algorithm for detecting referable diabetic retinopathy ({RDR}), defined as moderate and worse diabetic retinopathy, referable diabetic macular edema, or both, were generated based on the reference standard of the majority decision of the ophthalmologist panel. The algorithm was evaluated at 2 operating points selected from the development set, one selected for high specificity and another for high sensitivity.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Results{\textless}/h3{\textgreater}{\textless}p{\textgreater}The {EyePACS}-1 data set consisted of 9963 images from 4997 patients (mean age, 54.4 years; 62.2\% women; prevalence of {RDR}, 683/8878 fully gradable images [7.8\%]); the Messidor-2 data set had 1748 images from 874 patients (mean age, 57.6 years; 42.6\% women; prevalence of {RDR}, 254/1745 fully gradable images [14.6\%]). For detecting {RDR}, the algorithm had an area under the receiver operating curve of 0.991 (95\% {CI}, 0.988-0.993) for {EyePACS}-1 and 0.990 (95\% {CI}, 0.986-0.995) for Messidor-2. Using the first operating cut point with high specificity, for {EyePACS}-1, the sensitivity was 90.3\% (95\% {CI}, 87.5\%-92.7\%) and the specificity was 98.1\% (95\% {CI}, 97.8\%-98.5\%). For Messidor-2, the sensitivity was 87.0\% (95\% {CI}, 81.1\%-91.0\%) and the specificity was 98.5\% (95\% {CI}, 97.7\%-99.1\%). Using a second operating point with high sensitivity in the development set, for {EyePACS}-1 the sensitivity was 97.5\% and specificity was 93.4\% and for Messidor-2 the sensitivity was 96.1\% and specificity was 93.9\%.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Conclusions and Relevance{\textless}/h3{\textgreater}{\textless}p{\textgreater}In this evaluation of retinal fundus photographs from adults with diabetes, an algorithm based on deep machine learning had high sensitivity and specificity for detecting referable diabetic retinopathy. Further research is necessary to determine the feasibility of applying this algorithm in the clinical setting and to determine whether use of the algorithm could lead to improved care and outcomes compared with current ophthalmologic assessment.{\textless}/p{\textgreater}},
	pages = {2402--2410},
	number = {22},
	journaltitle = {{JAMA}},
	shortjournal = {{JAMA}},
	author = {Gulshan, Varun and Peng, Lily and Coram, Marc and Stumpe, Martin C. and Wu, Derek and Narayanaswamy, Arunachalam and Venugopalan, Subhashini and Widner, Kasumi and Madams, Tom and Cuadros, Jorge and Kim, Ramasamy and Raman, Rajiv and Nelson, Philip C. and Mega, Jessica L. and Webster, Dale R.},
	urldate = {2020-04-26},
	date = {2016-12-13},
	langid = {english},
	note = {Publisher: American Medical Association}
}


@inproceedings{jarrett_what_2009,
	title = {What is the best multi-stage architecture for object recognition?},
	doi = {10.1109/ICCV.2009.5459469},
	abstract = {In many recent object recognition systems, feature extraction stages are generally composed of a filter bank, a non-linear transformation, and some sort of feature pooling layer. Most systems use only one stage of feature extraction in which the filters are hard-wired, or two stages where the filters in one or both stages are learned in supervised or unsupervised mode. This paper addresses three questions: 1. How does the non-linearities that follow the filter banks influence the recognition accuracy? 2. does learning the filter banks in an unsupervised or supervised manner improve the performance over random filters or hardwired filters? 3. Is there any advantage to using an architecture with two stages of feature extraction, rather than one? We show that using non-linearities that include rectification and local contrast normalization is the single most important ingredient for good accuracy on object recognition benchmarks. We show that two stages of feature extraction yield better accuracy than one. Most surprisingly, we show that a two-stage system with random filters can yield almost 63\% recognition rate on Caltech-101, provided that the proper non-linearities and pooling layers are used. Finally, we show that with supervised refinement, the system achieves state-of-the-art performance on {NORB} dataset (5.6\%) and unsupervised pre-training followed by supervised refinement produces good accuracy on Caltech-101 ({\textgreater} 65\%), and the lowest known error rate on the undistorted, unprocessed {MNIST} dataset (0.53\%).},
	eventtitle = {2009 {IEEE} 12th International Conference on Computer Vision},
	pages = {2146--2153},
	booktitle = {2009 {IEEE} 12th International Conference on Computer Vision},
	author = {Jarrett, Kevin and Kavukcuoglu, Koray and Ranzato, Marc'Aurelio and {LeCun}, Yann},
	date = {2009-09},
	note = {{ISSN}: 2380-7504},
	keywords = {Brain modeling, Caltech-101, Error analysis, feature extraction, Feature extraction, feature pooling layer, feature rectification, filter bank, Filter bank, Gabor filters, Histograms, Image edge detection, Learning systems, local contrast normalization, multistage architecture, nonlinear transformation, {NORB} dataset, object recognition, Object recognition, Refining, supervised learning, unprocessed {MNIST} dataset, unsupervised learning}
}

@book{bishop_pattern_recognition_2006,
	author = {Bishop, Christopher M.},
	title = {Pattern Recognition and Machine Learning (Information Science and Statistics)},
	year = {2006},
	isbn = {0387310738},
	publisher = {Springer-Verlag},
	address = {Berlin, Heidelberg}
}

@COMMENT Blood vessel segmentation

@article{liskowski_segmenting_2016,
	title = {Segmenting Retinal Blood Vessels With Deep Neural Networks},
	volume = {35},
	issn = {1558-254X},
	doi = {10.1109/TMI.2016.2546227},
	abstract = {The condition of the vascular network of human eye is an important diagnostic factor in ophthalmology. Its segmentation in fundus imaging is a nontrivial task due to variable size of vessels, relatively low contrast, and potential presence of pathologies like microaneurysms and hemorrhages. Many algorithms, both unsupervised and supervised, have been proposed for this purpose in the past. We propose a supervised segmentation technique that uses a deep neural network trained on a large (up to 400 þinspace000) sample of examples preprocessed with global contrast normalization, zero-phase whitening, and augmented using geometric transformations and gamma corrections. Several variants of the method are considered, including structured prediction, where a network classifies multiple pixels simultaneously. When applied to standard benchmarks of fundus imaging, the {DRIVE}, {STARE}, and {CHASE} databases, the networks significantly outperform the previous algorithms on the area under {ROC} curve measure (up to {\textgreater} 0.99) and accuracy of classification (up to {\textgreater} 0.97). The method is also resistant to the phenomenon of central vessel reflex, sensitive in detection of fine vessels ( sensitivity {\textgreater} 0.87), and fares well on pathological cases.},
	pages = {2369--2380},
	number = {11},
	journaltitle = {{IEEE} Transactions on Medical Imaging},
	author = {Liskowski, Paweł and Krawiec, Krzysztof},
	date = {2016-11},
	note = {Conference Name: {IEEE} Transactions on Medical Imaging},
	keywords = {Biomedical imaging, blood vessels, Blood vessels, central vessel reflex, {CHASE} databases, Classification, Convolution, Databases, Databases, Factual, deep learning, deep neural networks, diagnostic factor, {DRIVE} databases, eye, feature learning, fundus, fundus imaging, gamma corrections, geometric transformations, global contrast normalization, hemorrhages, human eye, Humans, image classification, Image Interpretation, Computer-Assisted, image segmentation, Image segmentation, medical image processing, microaneurysms, neural nets, neural networks, Neural networks, Neural Networks (Computer), nontrivial task, ophthalmology, Pathology, retina, retinal blood vessel segmentation, Retinal Vessels, retinopathy, {ROC} curve, sensitivity analysis, {STARE} databases, structured prediction, Supervised Machine Learning, supervised segmentation, unsupervised learning, vascular network, vessel segmentation, zero-phase whitening}
}

@article{fraz_blood_2012,
	title = {Blood vessel segmentation methodologies in retinal images – A survey},
	volume = {108},
	issn = {0169-2607},
	url = {http://www.sciencedirect.com/science/article/pii/S0169260712000843},
	doi = {10.1016/j.cmpb.2012.03.009},
	abstract = {Retinal vessel segmentation algorithms are a fundamental component of automatic retinal disease screening systems. This work examines the blood vessel segmentation methodologies in two dimensional retinal images acquired from a fundus camera and a survey of techniques is presented. The aim of this paper is to review, analyze and categorize the retinal vessel extraction algorithms, techniques and methodologies, giving a brief description, highlighting the key points and the performance measures. We intend to give the reader a framework for the existing research; to introduce the range of retinal vessel segmentation algorithms; to discuss the current trends and future directions and summarize the open problems. The performance of algorithms is compared and analyzed on two publicly available databases ({DRIVE} and {STARE}) of retinal images using a number of measures which include accuracy, true positive rate, false positive rate, sensitivity, specificity and area under receiver operating characteristic ({ROC}) curve.},
	pages = {407--433},
	number = {1},
	journaltitle = {Computer Methods and Programs in Biomedicine},
	shortjournal = {Computer Methods and Programs in Biomedicine},
	author = {Fraz, M. M. and Remagnino, P. and Hoppe, A. and Uyyanonvara, B. and Rudnicka, A. R. and Owen, C. G. and Barman, S. A.},
	urldate = {2020-04-26},
	date = {2012-10-01},
	langid = {english},
	keywords = {Image segmentation, Blood vessel segmentation, Medical imaging, Retinal images, Retinopathy, Survey}
}

@inproceedings{fu_retinal_2016,
	title = {Retinal vessel segmentation via deep learning network and fully-connected conditional random fields},
	doi = {10.1109/ISBI.2016.7493362},
	abstract = {Vessel segmentation is a key step for various medical applications. This paper introduces the deep learning architecture to improve the performance of retinal vessel segmentation. Deep learning architecture has been demonstrated having the powerful ability in automatically learning the rich hierarchical representations. In this paper, we formulate the vessel segmentation to a boundary detection problem, and utilize the fully convolutional neural networks ({CNNs}) to generate a vessel probability map. Our vessel probability map distinguishes the vessels and background in the inadequate contrast region, and has robustness to the pathological regions in the fundus image. Moreover, a fully-connected Conditional Random Fields ({CRFs}) is also employed to combine the discriminative vessel probability map and long-range interactions between pixels. Finally, a binary vessel segmentation result is obtained by our method. We show that our proposed method achieve a state-of-the-art vessel segmentation performance on the {DRIVE} and {STARE} datasets.},
	eventtitle = {2016 {IEEE} 13th International Symposium on Biomedical Imaging ({ISBI})},
	pages = {698--701},
	booktitle = {2016 {IEEE} 13th International Symposium on Biomedical Imaging ({ISBI})},
	author = {Fu, Huazhu and Xu, Yanwu and Wong, Damon Wing Kee and Liu, Jiang},
	date = {2016-04},
	note = {{ISSN}: 1945-8452},
	keywords = {blood vessels, eye, image segmentation, Image segmentation, medical image processing, neural nets, Neural networks, Pathology, binary vessel segmentation, boundary detection, Computer architecture, Conditional Random Fields, convolutional neural networks, Convolutional Neural Networks, deep learning network, {DRIVE} dataset, fully-connected conditional random fields, fundus image, Machine learning, pathological region, retinal vessel segmentation, Retinal vessels, {STARE} dataset, vessel probability map, Vessel segmentation}
}

@inproceedings{fu_deepvessel_2016,
	location = {Cham},
	title = {{DeepVessel}: Retinal Vessel Segmentation via Deep Learning and Conditional Random Field},
	isbn = {978-3-319-46723-8},
	doi = {10.1007/978-3-319-46723-8_16},
	series = {Lecture Notes in Computer Science},
	shorttitle = {{DeepVessel}},
	abstract = {Retinal vessel segmentation is a fundamental step for various ocular imaging applications. In this paper, we formulate the retinal vessel segmentation problem as a boundary detection task and solve it using a novel deep learning architecture. Our method is based on two key ideas: (1) applying a multi-scale and multi-level Convolutional Neural Network ({CNN}) with a side-output layer to learn a rich hierarchical representation, and (2) utilizing a Conditional Random Field ({CRF}) to model the long-range interactions between pixels. We combine the {CNN} and {CRF} layers into an integrated deep network called {DeepVessel}. Our experiments show that the {DeepVessel} system achieves state-of-the-art retinal vessel segmentation performance on the {DRIVE}, {STARE}, and {CHASE}\_DB1 datasets with an efficient running time.},
	pages = {132--139},
	booktitle = {Medical Image Computing and Computer-Assisted Intervention – {MICCAI} 2016},
	publisher = {Springer International Publishing},
	author = {Fu, Huazhu and Xu, Yanwu and Lin, Stephen and Kee Wong, Damon Wing and Liu, Jiang},
	editor = {Ourselin, Sebastien and Joskowicz, Leo and Sabuncu, Mert R. and Unal, Gozde and Wells, William},
	date = {2016},
	langid = {english},
	keywords = {Conditional Random Field, Convolutional Neural Network, Deep Neural Network, Recurrent Neural Network, Retinal Vessel}
}
@article{li_cross-modality_2016,
	title = {A Cross-Modality Learning Approach for Vessel Segmentation in Retinal Images},
	volume = {35},
	issn = {1558-254X},
	doi = {10.1109/TMI.2015.2457891},
	abstract = {This paper presents a new supervised method for vessel segmentation in retinal images. This method remolds the task of segmentation as a problem of cross-modality data transformation from retinal image to vessel map. A wide and deep neural network with strong induction ability is proposed to model the transformation, and an efficient training strategy is presented. Instead of a single label of the center pixel, the network can output the label map of all pixels for a given image patch. Our approach outperforms reported state-of-the-art methods in terms of sensitivity, specificity and accuracy. The result of cross-training evaluation indicates its robustness to the training set. The approach needs no artificially designed feature and no preprocessing step, reducing the impact of subjective factors. The proposed method has the potential for application in image diagnosis of ophthalmologic diseases, and it may provide a new, general, high-performance computing framework for image segmentation.},
	pages = {109--118},
	number = {1},
	journaltitle = {{IEEE} Transactions on Medical Imaging},
	author = {Li, Qiaoliang and Feng, Bowei and Xie, {LinPei} and Liang, Ping and Zhang, Huisheng and Wang, Tianfu},
	date = {2016-01},
	note = {Conference Name: {IEEE} Transactions on Medical Imaging},
	keywords = {Accuracy, Algorithms, center pixel, computing framework, Cross-modality learning, cross-modality learning approach, cross-training evaluation, Databases, Factual, deep learning, Deformable models, eye, Feature extraction, Humans, image diagnosis, Image Processing, Computer-Assisted, image segmentation, Image segmentation, induction ability, Machine Learning, medical image processing, neural nets, neural network, Neural networks, ophthalmologic diseases, Retina, retinal image, retinal images, Retinal Vessels, Training, vessel map, vessel segmentation}
}

@article{jiang_retinal_2018,
	title = {Retinal blood vessel segmentation using fully convolutional network with transfer learning},
	volume = {68},
	issn = {0895-6111},
	url = {http://www.sciencedirect.com/science/article/pii/S0895611118302313},
	doi = {10.1016/j.compmedimag.2018.04.005},
	abstract = {Since the retinal blood vessel has been acknowledged as an indispensable element in both ophthalmological and cardiovascular disease diagnosis, the accurate segmentation of the retinal vessel tree has become the prerequisite step for automated or computer-aided diagnosis systems. In this paper, a supervised method is presented based on a pre-trained fully convolutional network through transfer learning. This proposed method has simplified the typical retinal vessel segmentation problem from full-size image segmentation to regional vessel element recognition and result merging. Meanwhile, additional unsupervised image post-processing techniques are applied to this proposed method so as to refine the final result. Extensive experiments have been conducted on {DRIVE}, {STARE}, {CHASE}\_DB1 and {HRF} databases, and the accuracy of the cross-database test on these four databases is state-of-the-art, which also presents the high robustness of the proposed approach. This successful result has not only contributed to the area of automated retinal blood vessel segmentation but also supports the effectiveness of transfer learning when applying deep learning technique to medical imaging.},
	pages = {1--15},
	journaltitle = {Computerized Medical Imaging and Graphics},
	shortjournal = {Computerized Medical Imaging and Graphics},
	author = {Jiang, Zhexin and Zhang, Hao and Wang, Yi and Ko, Seok-Bum},
	urldate = {2020-04-27},
	date = {2018-09-01},
	langid = {english},
	keywords = {Deep learning, Fully convolutional network, Pre-trained model, Retinal blood vessel segmentation, Transfer learning}
}

@COMMENT Dice's coefficient

@article{dice_measures_1945,
	title = {Measures of the Amount of Ecologic Association Between Species},
	volume = {26},
	rights = {© 1945 by the Ecological Society of America},
	issn = {1939-9170},
	url = {https://esajournals.onlinelibrary.wiley.com/doi/abs/10.2307/1932409},
	doi = {10.2307/1932409},
	pages = {297--302},
	number = {3},
	journaltitle = {Ecology},
	author = {Dice, Lee R.},
	urldate = {2020-04-27},
	date = {1945},
	langid = {english},
	note = {\_eprint: https://esajournals.onlinelibrary.wiley.com/doi/pdf/10.2307/1932409}
}

@COMMENT images
@Online {adaptive_image,
	title = {The Indiana Adaptive Optics SLOs},
	date = {2020-04-27},
	url = {https://www.opt.indiana.edu/people/faculty/burns/CenterForOphthalmicImaging/AOSLO.htm#System_Design_and_Performance},
	urldate = {2020-04-27}
}


@article{burns_adaptive_2019,
	title = {Adaptive optics imaging of the human retina},
	volume = {68},
	issn = {1350-9462},
	url = {http://www.sciencedirect.com/science/article/pii/S1350946218300405},
	doi = {10.1016/j.preteyeres.2018.08.002},
	abstract = {Adaptive Optics ({AO}) retinal imaging has provided revolutionary tools to scientists and clinicians for studying retinal structure and function in the living eye. From animal models to clinical patients, {AO} imaging is changing the way scientists are approaching the study of the retina. By providing cellular and subcellular details without the need for histology, it is now possible to perform large scale studies as well as to understand how an individual retina changes over time. Because {AO} retinal imaging is non-invasive and when performed with near-{IR} wavelengths both safe and easily tolerated by patients, it holds promise for being incorporated into clinical trials providing cell specific approaches to monitoring diseases and therapeutic interventions. {AO} is being used to enhance the ability of {OCT}, fluorescence imaging, and reflectance imaging. By incorporating imaging that is sensitive to differences in the scattering properties of retinal tissue, it is especially sensitive to disease, which can drastically impact retinal tissue properties. This review examines human {AO} retinal imaging with a concentration on the use of the Adaptive Optics Scanning Laser Ophthalmoscope ({AOSLO}). It first covers the background and the overall approaches to human {AO} retinal imaging, and the technology involved, and then concentrates on using {AO} retinal imaging to study the structure and function of the retina.},
	pages = {1--30},
	journaltitle = {Progress in Retinal and Eye Research},
	shortjournal = {Progress in Retinal and Eye Research},
	author = {Burns, Stephen A. and Elsner, Ann E. and Sapoznik, Kaitlyn A. and Warner, Raymond L. and Gast, Thomas J.},
	urldate = {2020-04-27},
	date = {2019-01-01},
	langid = {english},
	keywords = {Blood flow, Imaging, Ophthalmoscopy, Photoreceptors, Retina, Retinal degenerations, Vascular disease}
}